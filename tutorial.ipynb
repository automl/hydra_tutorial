{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML Fall School 2023 Hydra Hands-On\n",
    "\n",
    "Welcome to our tutorial session on [hydra](hydra.cc)! üêç\n",
    "Hydra is a tool for configuring and running your experiments and optimization is seemlessly integrated.\n",
    "\n",
    "Hydra can:\n",
    "\n",
    "* Hierarchical configuration composable from multiple sources\n",
    "* Configuration can be specified or overridden from the command line\n",
    "* Dynamic command line tab completion\n",
    "* Run your application locally or launch it to run remotely\n",
    "* Run multiple jobs with different arguments with a single command\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Classical Training Pipeline\n",
    "\n",
    "(This part of the tutorial is the same as in the SMAC tutorial).\n",
    "\n",
    "We'll start with your classical optimization task.\n",
    "The task is to optimize the hyperparameters of a [sklearn.neural_network.MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) on the [digits](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) dataset. Usually we have some training pipeline with a dataset, a configured model[^1] and some validation procedure to check for generalization performance like this:\n",
    "\n",
    "\n",
    "[^1]: If we check out the documentation, we will see that loads of design decisions (hyperparameters) are already set to a default value for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">warnings</span>\n",
       "\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn</span> <span class=\"kn\">import</span> <span class=\"n\">datasets</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">ConvergenceWarning</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">cross_val_score</span><span class=\"p\">,</span> <span class=\"n\">train_test_split</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.neural_network</span> <span class=\"kn\">import</span> <span class=\"n\">MLPClassifier</span>\n",
       "\n",
       "<span class=\"n\">warnings</span><span class=\"o\">.</span><span class=\"n\">filterwarnings</span><span class=\"p\">(</span><span class=\"s2\">&quot;ignore&quot;</span><span class=\"p\">,</span> <span class=\"n\">category</span><span class=\"o\">=</span><span class=\"n\">ConvergenceWarning</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># We load the digits dataset</span>\n",
       "<span class=\"n\">digits</span> <span class=\"o\">=</span> <span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">load_digits</span><span class=\"p\">()</span>\n",
       "<span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">digits</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">digits</span><span class=\"o\">.</span><span class=\"n\">target</span>\n",
       "\n",
       "<span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">X_test</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">y_test</span> <span class=\"o\">=</span> <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">test_size</span><span class=\"o\">=</span><span class=\"mf\">0.33</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">train_mlp</span><span class=\"p\">()</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">float</span><span class=\"p\">:</span>\n",
       "    <span class=\"c1\"># we want to have reproducible training</span>\n",
       "    <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"mi\">1234</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># for illustrative purposes, you can reduce max_iter drastically here</span>\n",
       "    <span class=\"n\">classifier</span> <span class=\"o\">=</span> <span class=\"n\">MLPClassifier</span><span class=\"p\">(</span><span class=\"n\">hidden_layer_sizes</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,),</span> <span class=\"n\">max_iter</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s2\">&quot;relu&quot;</span><span class=\"p\">,</span> <span class=\"n\">solver</span><span class=\"o\">=</span><span class=\"s2\">&quot;adam&quot;</span><span class=\"p\">)</span>\n",
       "    <span class=\"n\">scores</span> <span class=\"o\">=</span> <span class=\"n\">cross_val_score</span><span class=\"p\">(</span><span class=\"n\">classifier</span><span class=\"p\">,</span> <span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">cv</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">return</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">scores</span><span class=\"p\">)</span>  <span class=\"c1\"># mean accuracy over folds</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;__main__&quot;</span><span class=\"p\">:</span>\n",
       "    <span class=\"c1\"># Ignore the warnings for now:)</span>\n",
       "    <span class=\"n\">cv_loss</span> <span class=\"o\">=</span> <span class=\"n\">train_mlp</span><span class=\"p\">()</span>\n",
       "    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Cross_validation accuaracy on digits </span><span class=\"si\">{</span><span class=\"n\">cv_loss</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{warnings}\n",
       "\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn} \\PY{k+kn}{import} \\PY{n}{datasets}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{exceptions} \\PY{k+kn}{import} \\PY{n}{ConvergenceWarning}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{cross\\PYZus{}val\\PYZus{}score}\\PY{p}{,} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{neural\\PYZus{}network} \\PY{k+kn}{import} \\PY{n}{MLPClassifier}\n",
       "\n",
       "\\PY{n}{warnings}\\PY{o}{.}\\PY{n}{filterwarnings}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{ignore}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{category}\\PY{o}{=}\\PY{n}{ConvergenceWarning}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} We load the digits dataset}\n",
       "\\PY{n}{digits} \\PY{o}{=} \\PY{n}{datasets}\\PY{o}{.}\\PY{n}{load\\PYZus{}digits}\\PY{p}{(}\\PY{p}{)}\n",
       "\\PY{n}{X}\\PY{p}{,} \\PY{n}{y} \\PY{o}{=} \\PY{n}{digits}\\PY{o}{.}\\PY{n}{data}\\PY{p}{,} \\PY{n}{digits}\\PY{o}{.}\\PY{n}{target}\n",
       "\n",
       "\\PY{n}{X\\PYZus{}train}\\PY{p}{,} \\PY{n}{X\\PYZus{}test}\\PY{p}{,} \\PY{n}{y\\PYZus{}train}\\PY{p}{,} \\PY{n}{y\\PYZus{}test} \\PY{o}{=} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\\PY{p}{(}\\PY{n}{X}\\PY{p}{,} \\PY{n}{y}\\PY{p}{,} \\PY{n}{test\\PYZus{}size}\\PY{o}{=}\\PY{l+m+mf}{0.33}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{train\\PYZus{}mlp}\\PY{p}{(}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n+nb}{float}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} we want to have reproducible training}\n",
       "    \\PY{n}{np}\\PY{o}{.}\\PY{n}{random}\\PY{o}{.}\\PY{n}{seed}\\PY{p}{(}\\PY{n}{seed}\\PY{o}{=}\\PY{l+m+mi}{1234}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} for illustrative purposes, you can reduce max\\PYZus{}iter drastically here}\n",
       "    \\PY{n}{classifier} \\PY{o}{=} \\PY{n}{MLPClassifier}\\PY{p}{(}\\PY{n}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{o}{=}\\PY{p}{(}\\PY{l+m+mi}{100}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{max\\PYZus{}iter}\\PY{o}{=}\\PY{l+m+mi}{100}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{relu}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{solver}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{adam}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "    \\PY{n}{scores} \\PY{o}{=} \\PY{n}{cross\\PYZus{}val\\PYZus{}score}\\PY{p}{(}\\PY{n}{classifier}\\PY{p}{,} \\PY{n}{X\\PYZus{}train}\\PY{p}{,} \\PY{n}{y\\PYZus{}train}\\PY{p}{,} \\PY{n}{cv}\\PY{o}{=}\\PY{l+m+mi}{5}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{return} \\PY{n}{np}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{n}{scores}\\PY{p}{)}  \\PY{c+c1}{\\PYZsh{} mean accuracy over folds}\n",
       "\n",
       "\n",
       "\\PY{k}{if} \\PY{n+nv+vm}{\\PYZus{}\\PYZus{}name\\PYZus{}\\PYZus{}} \\PY{o}{==} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZus{}\\PYZus{}main\\PYZus{}\\PYZus{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} Ignore the warnings for now:)}\n",
       "    \\PY{n}{cv\\PYZus{}loss} \\PY{o}{=} \\PY{n}{train\\PYZus{}mlp}\\PY{p}{(}\\PY{p}{)}\n",
       "    \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Cross\\PYZus{}validation accuaracy on digits }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{cv\\PYZus{}loss}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import warnings\n",
       "\n",
       "import numpy as np\n",
       "from sklearn import datasets\n",
       "from sklearn.exceptions import ConvergenceWarning\n",
       "from sklearn.model_selection import cross_val_score, train_test_split\n",
       "from sklearn.neural_network import MLPClassifier\n",
       "\n",
       "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
       "\n",
       "# We load the digits dataset\n",
       "digits = datasets.load_digits()\n",
       "X, y = digits.data, digits.target\n",
       "\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
       "\n",
       "\n",
       "def train_mlp() -> float:\n",
       "    # we want to have reproducible training\n",
       "    np.random.seed(seed=1234)\n",
       "\n",
       "    # for illustrative purposes, you can reduce max_iter drastically here\n",
       "    classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=100, activation=\"relu\", solver=\"adam\")\n",
       "    scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
       "\n",
       "    return np.mean(scores)  # mean accuracy over folds\n",
       "\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    # Ignore the warnings for now:)\n",
       "    cv_loss = train_mlp()\n",
       "    print(f\"Cross_validation accuaracy on digits {cv_loss}\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Code\n",
    "\n",
    "Code(filename=\"hydra_tutorial/classic_pipeline_hardcoded.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_validation accuaracy on digits 0.9625795297372062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline_hardcoded.py'], returncode=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.run(\"python hydra_tutorial/classic_pipeline_hardcoded.py\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You can ignore the errors above regarding not converging for now.\n",
    "\n",
    "What we can see in this example is that we hardcoded many (hyper-)parameters. But maybe we would like to vary them? So let's adapt our `train_mlp` function!\n",
    "We will use a dict-like object to hold all our parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">warnings</span>\n",
       "\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">omegaconf</span> <span class=\"kn\">import</span> <span class=\"n\">DictConfig</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">rich</span> <span class=\"kn\">import</span> <span class=\"n\">inspect</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">rich</span> <span class=\"kn\">import</span> <span class=\"nb\">print</span> <span class=\"k\">as</span> <span class=\"n\">printr</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn</span> <span class=\"kn\">import</span> <span class=\"n\">datasets</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">ConvergenceWarning</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">cross_val_score</span><span class=\"p\">,</span> <span class=\"n\">train_test_split</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.neural_network</span> <span class=\"kn\">import</span> <span class=\"n\">MLPClassifier</span>\n",
       "\n",
       "<span class=\"n\">warnings</span><span class=\"o\">.</span><span class=\"n\">filterwarnings</span><span class=\"p\">(</span><span class=\"s2\">&quot;ignore&quot;</span><span class=\"p\">,</span> <span class=\"n\">category</span><span class=\"o\">=</span><span class=\"n\">ConvergenceWarning</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># We load the digits dataset</span>\n",
       "<span class=\"n\">digits</span> <span class=\"o\">=</span> <span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">load_digits</span><span class=\"p\">()</span>\n",
       "<span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">digits</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">digits</span><span class=\"o\">.</span><span class=\"n\">target</span>\n",
       "\n",
       "<span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">X_test</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">y_test</span> <span class=\"o\">=</span> <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">test_size</span><span class=\"o\">=</span><span class=\"mf\">0.33</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">train_mlp</span><span class=\"p\">(</span><span class=\"n\">cfg</span><span class=\"p\">:</span> <span class=\"n\">DictConfig</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">float</span><span class=\"p\">:</span>\n",
       "    <span class=\"c1\"># we want to have reproducible training</span>\n",
       "    <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># for illustrative purposes, you can reduce max_iter drastically here</span>\n",
       "    <span class=\"n\">classifier</span> <span class=\"o\">=</span> <span class=\"n\">MLPClassifier</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">hidden_layer_sizes</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">hidden_layer_sizes</span><span class=\"p\">,</span> <span class=\"n\">max_iter</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">max_iter</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">activation</span><span class=\"p\">,</span> <span class=\"n\">solver</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">solver</span>\n",
       "    <span class=\"p\">)</span>\n",
       "    <span class=\"n\">scores</span> <span class=\"o\">=</span> <span class=\"n\">cross_val_score</span><span class=\"p\">(</span><span class=\"n\">classifier</span><span class=\"p\">,</span> <span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">cv</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">return</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">scores</span><span class=\"p\">)</span>  <span class=\"c1\"># mean accuracy over folds</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;__main__&quot;</span><span class=\"p\">:</span>\n",
       "    <span class=\"c1\"># Ignore the warnings for now:)</span>\n",
       "    <span class=\"c1\"># We can easily create a DictConfig object with dict-like syntax</span>\n",
       "    <span class=\"c1\"># We can have almost any type in here</span>\n",
       "    <span class=\"n\">cfg</span> <span class=\"o\">=</span> <span class=\"n\">DictConfig</span><span class=\"p\">(</span>\n",
       "        <span class=\"p\">{</span>\n",
       "            <span class=\"s2\">&quot;seed&quot;</span><span class=\"p\">:</span> <span class=\"mi\">1234</span><span class=\"p\">,</span>\n",
       "            <span class=\"s2\">&quot;hidden_layer_sizes&quot;</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,),</span>\n",
       "            <span class=\"s2\">&quot;max_iter&quot;</span><span class=\"p\">:</span> <span class=\"mi\">100</span><span class=\"p\">,</span>\n",
       "            <span class=\"s2\">&quot;activation&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;relu&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"s2\">&quot;solver&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;adam&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"p\">}</span>\n",
       "    <span class=\"p\">)</span>\n",
       "    <span class=\"n\">inspect</span><span class=\"p\">(</span><span class=\"n\">cfg</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"n\">cv_loss</span> <span class=\"o\">=</span> <span class=\"n\">train_mlp</span><span class=\"p\">(</span><span class=\"n\">cfg</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"p\">)</span>\n",
       "    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Cross_validation accuaracy on digits </span><span class=\"si\">{</span><span class=\"n\">cv_loss</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{warnings}\n",
       "\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{omegaconf} \\PY{k+kn}{import} \\PY{n}{DictConfig}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{rich} \\PY{k+kn}{import} \\PY{n}{inspect}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{rich} \\PY{k+kn}{import} \\PY{n+nb}{print} \\PY{k}{as} \\PY{n}{printr}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn} \\PY{k+kn}{import} \\PY{n}{datasets}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{exceptions} \\PY{k+kn}{import} \\PY{n}{ConvergenceWarning}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{cross\\PYZus{}val\\PYZus{}score}\\PY{p}{,} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{neural\\PYZus{}network} \\PY{k+kn}{import} \\PY{n}{MLPClassifier}\n",
       "\n",
       "\\PY{n}{warnings}\\PY{o}{.}\\PY{n}{filterwarnings}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{ignore}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{category}\\PY{o}{=}\\PY{n}{ConvergenceWarning}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} We load the digits dataset}\n",
       "\\PY{n}{digits} \\PY{o}{=} \\PY{n}{datasets}\\PY{o}{.}\\PY{n}{load\\PYZus{}digits}\\PY{p}{(}\\PY{p}{)}\n",
       "\\PY{n}{X}\\PY{p}{,} \\PY{n}{y} \\PY{o}{=} \\PY{n}{digits}\\PY{o}{.}\\PY{n}{data}\\PY{p}{,} \\PY{n}{digits}\\PY{o}{.}\\PY{n}{target}\n",
       "\n",
       "\\PY{n}{X\\PYZus{}train}\\PY{p}{,} \\PY{n}{X\\PYZus{}test}\\PY{p}{,} \\PY{n}{y\\PYZus{}train}\\PY{p}{,} \\PY{n}{y\\PYZus{}test} \\PY{o}{=} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\\PY{p}{(}\\PY{n}{X}\\PY{p}{,} \\PY{n}{y}\\PY{p}{,} \\PY{n}{test\\PYZus{}size}\\PY{o}{=}\\PY{l+m+mf}{0.33}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{train\\PYZus{}mlp}\\PY{p}{(}\\PY{n}{cfg}\\PY{p}{:} \\PY{n}{DictConfig}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n+nb}{float}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} we want to have reproducible training}\n",
       "    \\PY{n}{np}\\PY{o}{.}\\PY{n}{random}\\PY{o}{.}\\PY{n}{seed}\\PY{p}{(}\\PY{n}{seed}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{seed}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} for illustrative purposes, you can reduce max\\PYZus{}iter drastically here}\n",
       "    \\PY{n}{classifier} \\PY{o}{=} \\PY{n}{MLPClassifier}\\PY{p}{(}\n",
       "        \\PY{n}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{p}{,} \\PY{n}{max\\PYZus{}iter}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{max\\PYZus{}iter}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{activation}\\PY{p}{,} \\PY{n}{solver}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{solver}\n",
       "    \\PY{p}{)}\n",
       "    \\PY{n}{scores} \\PY{o}{=} \\PY{n}{cross\\PYZus{}val\\PYZus{}score}\\PY{p}{(}\\PY{n}{classifier}\\PY{p}{,} \\PY{n}{X\\PYZus{}train}\\PY{p}{,} \\PY{n}{y\\PYZus{}train}\\PY{p}{,} \\PY{n}{cv}\\PY{o}{=}\\PY{l+m+mi}{5}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{return} \\PY{n}{np}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{n}{scores}\\PY{p}{)}  \\PY{c+c1}{\\PYZsh{} mean accuracy over folds}\n",
       "\n",
       "\n",
       "\\PY{k}{if} \\PY{n+nv+vm}{\\PYZus{}\\PYZus{}name\\PYZus{}\\PYZus{}} \\PY{o}{==} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZus{}\\PYZus{}main\\PYZus{}\\PYZus{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} Ignore the warnings for now:)}\n",
       "    \\PY{c+c1}{\\PYZsh{} We can easily create a DictConfig object with dict\\PYZhy{}like syntax}\n",
       "    \\PY{c+c1}{\\PYZsh{} We can have almost any type in here}\n",
       "    \\PY{n}{cfg} \\PY{o}{=} \\PY{n}{DictConfig}\\PY{p}{(}\n",
       "        \\PY{p}{\\PYZob{}}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{seed}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+m+mi}{1234}\\PY{p}{,}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{p}{(}\\PY{l+m+mi}{100}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{max\\PYZus{}iter}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+m+mi}{100}\\PY{p}{,}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{activation}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{relu}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{solver}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{adam}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{p}{\\PYZcb{}}\n",
       "    \\PY{p}{)}\n",
       "    \\PY{n}{inspect}\\PY{p}{(}\\PY{n}{cfg}\\PY{p}{)}\n",
       "\n",
       "    \\PY{n}{cv\\PYZus{}loss} \\PY{o}{=} \\PY{n}{train\\PYZus{}mlp}\\PY{p}{(}\\PY{n}{cfg}\\PY{o}{=}\\PY{n}{cfg}\\PY{p}{)}\n",
       "    \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Cross\\PYZus{}validation accuaracy on digits }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{cv\\PYZus{}loss}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import warnings\n",
       "\n",
       "import numpy as np\n",
       "from omegaconf import DictConfig\n",
       "from rich import inspect\n",
       "from rich import print as printr\n",
       "from sklearn import datasets\n",
       "from sklearn.exceptions import ConvergenceWarning\n",
       "from sklearn.model_selection import cross_val_score, train_test_split\n",
       "from sklearn.neural_network import MLPClassifier\n",
       "\n",
       "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
       "\n",
       "# We load the digits dataset\n",
       "digits = datasets.load_digits()\n",
       "X, y = digits.data, digits.target\n",
       "\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
       "\n",
       "\n",
       "def train_mlp(cfg: DictConfig) -> float:\n",
       "    # we want to have reproducible training\n",
       "    np.random.seed(seed=cfg.seed)\n",
       "\n",
       "    # for illustrative purposes, you can reduce max_iter drastically here\n",
       "    classifier = MLPClassifier(\n",
       "        hidden_layer_sizes=cfg.hidden_layer_sizes, max_iter=cfg.max_iter, activation=cfg.activation, solver=cfg.solver\n",
       "    )\n",
       "    scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
       "\n",
       "    return np.mean(scores)  # mean accuracy over folds\n",
       "\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    # Ignore the warnings for now:)\n",
       "    # We can easily create a DictConfig object with dict-like syntax\n",
       "    # We can have almost any type in here\n",
       "    cfg = DictConfig(\n",
       "        {\n",
       "            \"seed\": 1234,\n",
       "            \"hidden_layer_sizes\": (100,),\n",
       "            \"max_iter\": 100,\n",
       "            \"activation\": \"relu\",\n",
       "            \"solver\": \"adam\",\n",
       "        }\n",
       "    )\n",
       "    inspect(cfg)\n",
       "\n",
       "    cv_loss = train_mlp(cfg=cfg)\n",
       "    print(f\"Cross_validation accuaracy on digits {cv_loss}\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Code(filename=\"hydra_tutorial/classic_pipeline_stillhardcoded.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m‚ï≠‚îÄ\u001b[0m\u001b[34m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[34m \u001b[0m\u001b[1;34m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'omegaconf.dictconfig.DictConfig'\u001b[0m\u001b[1;34m>\u001b[0m\u001b[34m \u001b[0m\u001b[34m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[34m‚îÄ‚ïÆ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m \u001b[32m‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\u001b[0m \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m \u001b[32m‚îÇ\u001b[0m \u001b[1m{\u001b[0m\u001b[32m'seed'\u001b[0m: \u001b[1;36m1234\u001b[0m, \u001b[32m'hidden_layer_sizes'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'max_iter'\u001b[0m: \u001b[1;36m100\u001b[0m,             \u001b[32m‚îÇ\u001b[0m \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m \u001b[32m‚îÇ\u001b[0m \u001b[32m'activation'\u001b[0m: \u001b[32m'relu'\u001b[0m, \u001b[32m'solver'\u001b[0m: \u001b[32m'adam'\u001b[0m\u001b[1m}\u001b[0m                                  \u001b[32m‚îÇ\u001b[0m \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m \u001b[32m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄÔøΩÔøΩ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m                                                                              \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m         \u001b[3;33mactivation\u001b[0m = \u001b[32m'relu'\u001b[0m                                                  \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m \u001b[3;33mhidden_layer_sizes\u001b[0m = \u001b[1m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1m]\u001b[0m                                                   \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m           \u001b[3;33mmax_iter\u001b[0m = \u001b[1;36m100\u001b[0m                                                     \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m               \u001b[3;33mseed\u001b[0m = \u001b[1;36m1234\u001b[0m                                                    \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m             \u001b[3;33msolver\u001b[0m = \u001b[32m'adam'\u001b[0m                                                  \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄÔøΩÔøΩ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
      "Cross_validation accuaracy on digits 0.9625795297372062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline_stillhardcoded.py'], returncode=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\"python hydra_tutorial/classic_pipeline_stillhardcoded.py\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's nice but let's vary the parameters with hydra!\n",
    "Hydra can wrap your main function and pass parameters from the command line or configuration files for you -- without the hassle of writing an argument parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">warnings</span>\n",
       "\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">hydra</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">omegaconf</span> <span class=\"kn\">import</span> <span class=\"n\">DictConfig</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn</span> <span class=\"kn\">import</span> <span class=\"n\">datasets</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">ConvergenceWarning</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">cross_val_score</span><span class=\"p\">,</span> <span class=\"n\">train_test_split</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.neural_network</span> <span class=\"kn\">import</span> <span class=\"n\">MLPClassifier</span>\n",
       "\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">hydra_tutorial.utils</span> <span class=\"kn\">import</span> <span class=\"n\">dump_logs</span>\n",
       "\n",
       "<span class=\"n\">warnings</span><span class=\"o\">.</span><span class=\"n\">filterwarnings</span><span class=\"p\">(</span><span class=\"s2\">&quot;ignore&quot;</span><span class=\"p\">,</span> <span class=\"n\">category</span><span class=\"o\">=</span><span class=\"n\">ConvergenceWarning</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># We load the digits dataset</span>\n",
       "<span class=\"n\">digits</span> <span class=\"o\">=</span> <span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">load_digits</span><span class=\"p\">()</span>\n",
       "<span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">digits</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">digits</span><span class=\"o\">.</span><span class=\"n\">target</span>\n",
       "\n",
       "<span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">X_test</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">y_test</span> <span class=\"o\">=</span> <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">test_size</span><span class=\"o\">=</span><span class=\"mf\">0.33</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "\n",
       "\n",
       "<span class=\"nd\">@hydra</span><span class=\"o\">.</span><span class=\"n\">main</span><span class=\"p\">(</span><span class=\"n\">version_base</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">config_path</span><span class=\"o\">=</span><span class=\"s2\">&quot;configs&quot;</span><span class=\"p\">,</span> <span class=\"n\">config_name</span><span class=\"o\">=</span><span class=\"s2\">&quot;base&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"k\">def</span> <span class=\"nf\">train_mlp</span><span class=\"p\">(</span><span class=\"n\">cfg</span><span class=\"p\">:</span> <span class=\"n\">DictConfig</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">float</span><span class=\"p\">:</span>\n",
       "    <span class=\"n\">warnings</span><span class=\"o\">.</span><span class=\"n\">filterwarnings</span><span class=\"p\">(</span><span class=\"s2\">&quot;ignore&quot;</span><span class=\"p\">,</span> <span class=\"n\">category</span><span class=\"o\">=</span><span class=\"n\">ConvergenceWarning</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># we want to have reproducible training</span>\n",
       "    <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># for illustrative purposes, you can reduce max_iter drastically here</span>\n",
       "    <span class=\"n\">classifier</span> <span class=\"o\">=</span> <span class=\"n\">MLPClassifier</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">hidden_layer_sizes</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">hidden_layer_sizes</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">max_iter</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">max_iter</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">activation</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">solver</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">solver</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">alpha</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">alpha</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">)</span>\n",
       "    <span class=\"n\">scores</span> <span class=\"o\">=</span> <span class=\"n\">cross_val_score</span><span class=\"p\">(</span><span class=\"n\">classifier</span><span class=\"p\">,</span> <span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">cv</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"n\">mean_score</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">scores</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Mean accuracy: </span><span class=\"si\">{</span><span class=\"n\">mean_score</span><span class=\"si\">:</span><span class=\"s2\">.4f</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># Let&#39;s produce a log file</span>\n",
       "    <span class=\"n\">dump_logs</span><span class=\"p\">(</span><span class=\"n\">log_data</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s2\">&quot;mean_acc&quot;</span><span class=\"p\">:</span> <span class=\"n\">mean_score</span><span class=\"p\">},</span> <span class=\"n\">filename</span><span class=\"o\">=</span><span class=\"s2\">&quot;performance.jsonl&quot;</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">return</span> <span class=\"mi\">1</span> <span class=\"o\">-</span> <span class=\"n\">mean_score</span>  <span class=\"c1\"># mean accuracy over folds</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;__main__&quot;</span><span class=\"p\">:</span>\n",
       "    <span class=\"n\">train_mlp</span><span class=\"p\">()</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{warnings}\n",
       "\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{hydra}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{omegaconf} \\PY{k+kn}{import} \\PY{n}{DictConfig}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn} \\PY{k+kn}{import} \\PY{n}{datasets}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{exceptions} \\PY{k+kn}{import} \\PY{n}{ConvergenceWarning}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{cross\\PYZus{}val\\PYZus{}score}\\PY{p}{,} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{neural\\PYZus{}network} \\PY{k+kn}{import} \\PY{n}{MLPClassifier}\n",
       "\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{hydra\\PYZus{}tutorial}\\PY{n+nn}{.}\\PY{n+nn}{utils} \\PY{k+kn}{import} \\PY{n}{dump\\PYZus{}logs}\n",
       "\n",
       "\\PY{n}{warnings}\\PY{o}{.}\\PY{n}{filterwarnings}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{ignore}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{category}\\PY{o}{=}\\PY{n}{ConvergenceWarning}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} We load the digits dataset}\n",
       "\\PY{n}{digits} \\PY{o}{=} \\PY{n}{datasets}\\PY{o}{.}\\PY{n}{load\\PYZus{}digits}\\PY{p}{(}\\PY{p}{)}\n",
       "\\PY{n}{X}\\PY{p}{,} \\PY{n}{y} \\PY{o}{=} \\PY{n}{digits}\\PY{o}{.}\\PY{n}{data}\\PY{p}{,} \\PY{n}{digits}\\PY{o}{.}\\PY{n}{target}\n",
       "\n",
       "\\PY{n}{X\\PYZus{}train}\\PY{p}{,} \\PY{n}{X\\PYZus{}test}\\PY{p}{,} \\PY{n}{y\\PYZus{}train}\\PY{p}{,} \\PY{n}{y\\PYZus{}test} \\PY{o}{=} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\\PY{p}{(}\\PY{n}{X}\\PY{p}{,} \\PY{n}{y}\\PY{p}{,} \\PY{n}{test\\PYZus{}size}\\PY{o}{=}\\PY{l+m+mf}{0.33}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{n+nd}{@hydra}\\PY{o}{.}\\PY{n}{main}\\PY{p}{(}\\PY{n}{version\\PYZus{}base}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \\PY{n}{config\\PYZus{}path}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{configs}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{config\\PYZus{}name}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{base}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{k}{def} \\PY{n+nf}{train\\PYZus{}mlp}\\PY{p}{(}\\PY{n}{cfg}\\PY{p}{:} \\PY{n}{DictConfig}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n+nb}{float}\\PY{p}{:}\n",
       "    \\PY{n}{warnings}\\PY{o}{.}\\PY{n}{filterwarnings}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{ignore}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{category}\\PY{o}{=}\\PY{n}{ConvergenceWarning}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} we want to have reproducible training}\n",
       "    \\PY{n}{np}\\PY{o}{.}\\PY{n}{random}\\PY{o}{.}\\PY{n}{seed}\\PY{p}{(}\\PY{n}{seed}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{seed}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} for illustrative purposes, you can reduce max\\PYZus{}iter drastically here}\n",
       "    \\PY{n}{classifier} \\PY{o}{=} \\PY{n}{MLPClassifier}\\PY{p}{(}\n",
       "        \\PY{n}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{p}{,}\n",
       "        \\PY{n}{max\\PYZus{}iter}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{max\\PYZus{}iter}\\PY{p}{,}\n",
       "        \\PY{n}{activation}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{activation}\\PY{p}{,}\n",
       "        \\PY{n}{solver}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{solver}\\PY{p}{,}\n",
       "        \\PY{n}{alpha}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{alpha}\\PY{p}{,}\n",
       "    \\PY{p}{)}\n",
       "    \\PY{n}{scores} \\PY{o}{=} \\PY{n}{cross\\PYZus{}val\\PYZus{}score}\\PY{p}{(}\\PY{n}{classifier}\\PY{p}{,} \\PY{n}{X\\PYZus{}train}\\PY{p}{,} \\PY{n}{y\\PYZus{}train}\\PY{p}{,} \\PY{n}{cv}\\PY{o}{=}\\PY{l+m+mi}{5}\\PY{p}{)}\n",
       "\n",
       "    \\PY{n}{mean\\PYZus{}score} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{n}{scores}\\PY{p}{)}\n",
       "\n",
       "    \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Mean accuracy: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{mean\\PYZus{}score}\\PY{l+s+si}{:}\\PY{l+s+s2}{.4f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} Let\\PYZsq{}s produce a log file}\n",
       "    \\PY{n}{dump\\PYZus{}logs}\\PY{p}{(}\\PY{n}{log\\PYZus{}data}\\PY{o}{=}\\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{mean\\PYZus{}acc}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{n}{mean\\PYZus{}score}\\PY{p}{\\PYZcb{}}\\PY{p}{,} \\PY{n}{filename}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{performance.jsonl}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{return} \\PY{l+m+mi}{1} \\PY{o}{\\PYZhy{}} \\PY{n}{mean\\PYZus{}score}  \\PY{c+c1}{\\PYZsh{} mean accuracy over folds}\n",
       "\n",
       "\n",
       "\\PY{k}{if} \\PY{n+nv+vm}{\\PYZus{}\\PYZus{}name\\PYZus{}\\PYZus{}} \\PY{o}{==} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZus{}\\PYZus{}main\\PYZus{}\\PYZus{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:}\n",
       "    \\PY{n}{train\\PYZus{}mlp}\\PY{p}{(}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import warnings\n",
       "\n",
       "import hydra\n",
       "import numpy as np\n",
       "from omegaconf import DictConfig\n",
       "from sklearn import datasets\n",
       "from sklearn.exceptions import ConvergenceWarning\n",
       "from sklearn.model_selection import cross_val_score, train_test_split\n",
       "from sklearn.neural_network import MLPClassifier\n",
       "\n",
       "from hydra_tutorial.utils import dump_logs\n",
       "\n",
       "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
       "\n",
       "# We load the digits dataset\n",
       "digits = datasets.load_digits()\n",
       "X, y = digits.data, digits.target\n",
       "\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
       "\n",
       "\n",
       "@hydra.main(version_base=None, config_path=\"configs\", config_name=\"base\")\n",
       "def train_mlp(cfg: DictConfig) -> float:\n",
       "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
       "\n",
       "    # we want to have reproducible training\n",
       "    np.random.seed(seed=cfg.seed)\n",
       "\n",
       "    # for illustrative purposes, you can reduce max_iter drastically here\n",
       "    classifier = MLPClassifier(\n",
       "        hidden_layer_sizes=cfg.hidden_layer_sizes,\n",
       "        max_iter=cfg.max_iter,\n",
       "        activation=cfg.activation,\n",
       "        solver=cfg.solver,\n",
       "        alpha=cfg.alpha,\n",
       "    )\n",
       "    scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
       "\n",
       "    mean_score = np.mean(scores)\n",
       "\n",
       "    print(f\"Mean accuracy: {mean_score:.4f}\")\n",
       "\n",
       "    # Let's produce a log file\n",
       "    dump_logs(log_data={\"mean_acc\": mean_score}, filename=\"performance.jsonl\")\n",
       "\n",
       "    return 1 - mean_score  # mean accuracy over folds\n",
       "\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    train_mlp()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Code(filename=\"hydra_tutorial/classic_pipeline.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we let it run, let's have a look at the configuration file.\n",
    "This will be our default as decorated by hydra.\n",
    "\n",
    "## Interpolation\n",
    "\n",
    "Do you notice the `${varname}` directive? Hydra can interpolate variables from within the config composition.\n",
    "The variable does not even need to be in the same yaml file!\n",
    "We can easily make the output directory a composition of experiment parameters, e.g. seed.\n",
    "If you have dependent config parameters, it is easier to change *all* parameters and harder to overlook some.\n",
    "\n",
    "\n",
    "For the hydra pros: There is also the functionality of registering custom resolvers assigning values to a var in the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"c1\"># @package _global_</span>\n",
       "<span class=\"nt\">defaults</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">  </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">_self_</span>\n",
       "<span class=\"w\">  </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"nt\">override hydra/launcher</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">joblib</span>\n",
       "<span class=\"w\">  </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"nt\">override hydra/job_logging</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">colorlog</span>\n",
       "<span class=\"w\">  </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"nt\">override hydra/hydra_logging</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">colorlog</span>\n",
       "\n",
       "<span class=\"nt\">seed</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">1234</span>\n",
       "<span class=\"nt\">hidden_layer_sizes</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p p-Indicator\">[</span><span class=\"nv\">100</span><span class=\"p p-Indicator\">,]</span>\n",
       "<span class=\"nt\">max_iter</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">100</span>\n",
       "<span class=\"nt\">activation</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s\">&#39;relu&#39;</span>\n",
       "<span class=\"nt\">solver</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s\">&#39;adam&#39;</span>\n",
       "<span class=\"nt\">alpha</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">0.0001</span>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<span class=\"nt\">outdir</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">runs/${now:%Y-%m-%d}/${now:%H-%M-%S}</span>\n",
       "<span class=\"nt\">hydra</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">  </span><span class=\"nt\">run</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">    </span><span class=\"nt\">dir</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">${outdir}</span>\n",
       "<span class=\"w\">  </span><span class=\"nt\">sweep</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">    </span><span class=\"nt\">dir</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">${outdir}</span>\n",
       "<span class=\"w\">    </span><span class=\"c1\">#subdir: null # if this is not set, normally is the hydra job number</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{c+c1}{\\PYZsh{} @package \\PYZus{}global\\PYZus{}}\n",
       "\\PY{n+nt}{defaults}\\PY{p}{:}\n",
       "\\PY{+w}{  }\\PY{p+pIndicator}{\\PYZhy{}}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{\\PYZus{}self\\PYZus{}}\n",
       "\\PY{+w}{  }\\PY{p+pIndicator}{\\PYZhy{}}\\PY{+w}{ }\\PY{n+nt}{override hydra/launcher}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{joblib}\n",
       "\\PY{+w}{  }\\PY{p+pIndicator}{\\PYZhy{}}\\PY{+w}{ }\\PY{n+nt}{override hydra/job\\PYZus{}logging}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{colorlog}\n",
       "\\PY{+w}{  }\\PY{p+pIndicator}{\\PYZhy{}}\\PY{+w}{ }\\PY{n+nt}{override hydra/hydra\\PYZus{}logging}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{colorlog}\n",
       "\n",
       "\\PY{n+nt}{seed}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{1234}\n",
       "\\PY{n+nt}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{p}{:}\\PY{+w}{ }\\PY{p+pIndicator}{[}\\PY{n+nv}{100}\\PY{p+pIndicator}{,}\\PY{p+pIndicator}{]}\n",
       "\\PY{n+nt}{max\\PYZus{}iter}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{100}\n",
       "\\PY{n+nt}{activation}\\PY{p}{:}\\PY{+w}{ }\\PY{l+s}{\\PYZsq{}}\\PY{l+s}{relu}\\PY{l+s}{\\PYZsq{}}\n",
       "\\PY{n+nt}{solver}\\PY{p}{:}\\PY{+w}{ }\\PY{l+s}{\\PYZsq{}}\\PY{l+s}{adam}\\PY{l+s}{\\PYZsq{}}\n",
       "\\PY{n+nt}{alpha}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{0.0001}\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\\PY{n+nt}{outdir}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{runs/\\PYZdl{}\\PYZob{}now:\\PYZpc{}Y\\PYZhy{}\\PYZpc{}m\\PYZhy{}\\PYZpc{}d\\PYZcb{}/\\PYZdl{}\\PYZob{}now:\\PYZpc{}H\\PYZhy{}\\PYZpc{}M\\PYZhy{}\\PYZpc{}S\\PYZcb{}}\n",
       "\\PY{n+nt}{hydra}\\PY{p}{:}\n",
       "\\PY{+w}{  }\\PY{n+nt}{run}\\PY{p}{:}\n",
       "\\PY{+w}{    }\\PY{n+nt}{dir}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{\\PYZdl{}\\PYZob{}outdir\\PYZcb{}}\n",
       "\\PY{+w}{  }\\PY{n+nt}{sweep}\\PY{p}{:}\n",
       "\\PY{+w}{    }\\PY{n+nt}{dir}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{\\PYZdl{}\\PYZob{}outdir\\PYZcb{}}\n",
       "\\PY{+w}{    }\\PY{c+c1}{\\PYZsh{}subdir: null \\PYZsh{} if this is not set, normally is the hydra job number}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "# @package _global_\n",
       "defaults:\n",
       "  - _self_\n",
       "  - override hydra/launcher: joblib\n",
       "  - override hydra/job_logging: colorlog\n",
       "  - override hydra/hydra_logging: colorlog\n",
       "\n",
       "seed: 1234\n",
       "hidden_layer_sizes: [100,]\n",
       "max_iter: 100\n",
       "activation: 'relu'\n",
       "solver: 'adam'\n",
       "alpha: 0.0001\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "outdir: runs/${now:%Y-%m-%d}/${now:%H-%M-%S}\n",
       "hydra:\n",
       "  run:\n",
       "    dir: ${outdir}\n",
       "  sweep:\n",
       "    dir: ${outdir}\n",
       "    #subdir: null # if this is not set, normally is the hydra job number"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Code(filename=\"hydra_tutorial/configs/base.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.9626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline.py'], returncode=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\"python hydra_tutorial/classic_pipeline.py\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overrides on the Commandline\n",
    "Now we want to pass arguments via the commandline.\n",
    "This is easily possible with the [override syntax](https://hydra.cc/docs/advanced/override_grammar/basic/).\n",
    "Let's vary the hidden layer sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.8945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline.py', 'hidden_layer_sizes=[10,10,10]'], returncode=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\"python hydra_tutorial/classic_pipeline.py hidden_layer_sizes=[10,10,10]\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sweeps\n",
    "But what really comes in handy is the ability to grid of parameter settings.\n",
    "First, to factor out randomness we want to run different seeds.\n",
    "Then, we would like to check different settings, e.g. different hidden layer sizes and different activation functions.\n",
    "\n",
    "For this we will add a list of parameter values and the flag `-m` or `--multirun` to indicate that this is a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2023-11-28 10:08:57,996\u001b[0m][\u001b[35mHYDRA\u001b[0m] Joblib.Parallel(n_jobs=-1,backend=loky,prefer=processes,require=None,verbose=0,timeout=None,pre_dispatch=2*n_jobs,batch_size=auto,temp_folder=None,max_nbytes=None,mmap_mode=r) is launching 10 jobs\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:08:57,997\u001b[0m][\u001b[35mHYDRA\u001b[0m] Launching jobs, sweep output dir : runs/2023-11-28/10-08-57\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:08:57,997\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#0 : hidden_layer_sizes=[100] seed=1\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:08:57,997\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#1 : hidden_layer_sizes=[100] seed=2\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:08:57,997\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#2 : hidden_layer_sizes=[100] seed=3\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:08:57,997\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#3 : hidden_layer_sizes=[100] seed=4\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:08:57,997\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#4 : hidden_layer_sizes=[100] seed=5\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:08:57,997\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#5 : hidden_layer_sizes=[10,10,10] seed=1\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:08:57,997\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#6 : hidden_layer_sizes=[10,10,10] seed=2\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:08:57,997\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#7 : hidden_layer_sizes=[10,10,10] seed=3\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:08:57,997\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#8 : hidden_layer_sizes=[10,10,10] seed=4\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:08:57,997\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#9 : hidden_layer_sizes=[10,10,10] seed=5\u001b[0m\n",
      "Mean accuracy: 0.8661\n",
      "Mean accuracy: 0.8686\n",
      "Mean accuracy: 0.8678\n",
      "Mean accuracy: 0.8719\n",
      "Mean accuracy: 0.8412\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9601\n",
      "Mean accuracy: 0.9568\n",
      "Mean accuracy: 0.9509\n",
      "Mean accuracy: 0.9601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline.py', 'hidden_layer_sizes=[100],[10,10,10]', 'seed=range(1,6)', '-m'], returncode=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\n",
    "    \"python hydra_tutorial/classic_pipeline.py hidden_layer_sizes=[100],[10,10,10] seed=range(1,6) -m\".split(\" \")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launchers\n",
    "You can specifiy the number of workers on your local cluster via the config files.\n",
    "This config runs your parallel jobs with joblib.\n",
    "The config might look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"c1\"># @package _global_</span>\n",
       "<span class=\"nt\">defaults</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">  </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"nt\">override /hydra/launcher</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">joblib</span>\n",
       "\n",
       "<span class=\"nt\">hydra</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">  </span><span class=\"nt\">launcher</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">    </span><span class=\"nt\">n_jobs</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">4</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{c+c1}{\\PYZsh{} @package \\PYZus{}global\\PYZus{}}\n",
       "\\PY{n+nt}{defaults}\\PY{p}{:}\n",
       "\\PY{+w}{  }\\PY{p+pIndicator}{\\PYZhy{}}\\PY{+w}{ }\\PY{n+nt}{override /hydra/launcher}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{joblib}\n",
       "\n",
       "\\PY{n+nt}{hydra}\\PY{p}{:}\n",
       "\\PY{+w}{  }\\PY{n+nt}{launcher}\\PY{p}{:}\n",
       "\\PY{+w}{    }\\PY{n+nt}{n\\PYZus{}jobs}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{4}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "# @package _global_\n",
       "defaults:\n",
       "  - override /hydra/launcher: joblib\n",
       "\n",
       "hydra:\n",
       "  launcher:\n",
       "    n_jobs: 4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Code(filename=\"hydra_tutorial/configs/cluster/local.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2023-11-28 10:09:08,566\u001b[0m][\u001b[35mHYDRA\u001b[0m] Joblib.Parallel(n_jobs=4,backend=loky,prefer=processes,require=None,verbose=0,timeout=None,pre_dispatch=2*n_jobs,batch_size=auto,temp_folder=None,max_nbytes=None,mmap_mode=r) is launching 10 jobs\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:08,566\u001b[0m][\u001b[35mHYDRA\u001b[0m] Launching jobs, sweep output dir : runs/2023-11-28/10-09-07\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:08,566\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#0 : hidden_layer_sizes=[100] seed=1 +cluster=local\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:08,566\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#1 : hidden_layer_sizes=[100] seed=2 +cluster=local\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:08,567\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#2 : hidden_layer_sizes=[100] seed=3 +cluster=local\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:08,567\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#3 : hidden_layer_sizes=[100] seed=4 +cluster=local\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:08,567\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#4 : hidden_layer_sizes=[100] seed=5 +cluster=local\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:08,567\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#5 : hidden_layer_sizes=[10,10,10] seed=1 +cluster=local\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:08,567\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#6 : hidden_layer_sizes=[10,10,10] seed=2 +cluster=local\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:08,567\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#7 : hidden_layer_sizes=[10,10,10] seed=3 +cluster=local\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:08,567\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#8 : hidden_layer_sizes=[10,10,10] seed=4 +cluster=local\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:08,567\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#9 : hidden_layer_sizes=[10,10,10] seed=5 +cluster=local\u001b[0m\n",
      "Mean accuracy: 0.9601\n",
      "Mean accuracy: 0.9568\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9601\n",
      "Mean accuracy: 0.8661\n",
      "Mean accuracy: 0.8686\n",
      "Mean accuracy: 0.9509\n",
      "Mean accuracy: 0.8719\n",
      "Mean accuracy: 0.8412\n",
      "Mean accuracy: 0.8678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline.py', 'hidden_layer_sizes=[100],[10,10,10]', 'seed=range(1,6)', '+cluster=local', '-m'], returncode=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\n",
    "    \"python hydra_tutorial/classic_pipeline.py hidden_layer_sizes=[100],[10,10,10] seed=range(1,6) +cluster=local -m\".split(\n",
    "        \" \"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also dispatch parallel jobs on your slurm cluster with the following command:\n",
    "\n",
    "`python hydra_tutorial/classic_pipeline.py hidden_layer_sizes=[100],[10,10,10] seed=range(1,6) +cluster=slurm -m`\n",
    "\n",
    "and the corresponding config file looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"c1\"># @package _global_</span>\n",
       "<span class=\"nt\">defaults</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">  </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"nt\">override /hydra/launcher</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">submitit_slurm</span>\n",
       "\n",
       "<span class=\"c1\"># Check more possible options here:</span>\n",
       "<span class=\"c1\"># https://hydra.cc/docs/plugins/submitit_launcher/</span>\n",
       "<span class=\"nt\">hydra</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">  </span><span class=\"nt\">launcher</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">    </span><span class=\"c1\"># partition: normal  # Set your partition here</span>\n",
       "<span class=\"w\">    </span><span class=\"nt\">timeout_min</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">10</span>\n",
       "<span class=\"w\">    </span><span class=\"nt\">cpus_per_task</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">1</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{c+c1}{\\PYZsh{} @package \\PYZus{}global\\PYZus{}}\n",
       "\\PY{n+nt}{defaults}\\PY{p}{:}\n",
       "\\PY{+w}{  }\\PY{p+pIndicator}{\\PYZhy{}}\\PY{+w}{ }\\PY{n+nt}{override /hydra/launcher}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{submitit\\PYZus{}slurm}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Check more possible options here:}\n",
       "\\PY{c+c1}{\\PYZsh{} https://hydra.cc/docs/plugins/submitit\\PYZus{}launcher/}\n",
       "\\PY{n+nt}{hydra}\\PY{p}{:}\n",
       "\\PY{+w}{  }\\PY{n+nt}{launcher}\\PY{p}{:}\n",
       "\\PY{+w}{    }\\PY{c+c1}{\\PYZsh{} partition: normal  \\PYZsh{} Set your partition here}\n",
       "\\PY{+w}{    }\\PY{n+nt}{timeout\\PYZus{}min}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{10}\n",
       "\\PY{+w}{    }\\PY{n+nt}{cpus\\PYZus{}per\\PYZus{}task}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{1}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "# @package _global_\n",
       "defaults:\n",
       "  - override /hydra/launcher: submitit_slurm\n",
       "\n",
       "# Check more possible options here:\n",
       "# https://hydra.cc/docs/plugins/submitit_launcher/\n",
       "hydra:\n",
       "  launcher:\n",
       "    # partition: normal  # Set your partition here\n",
       "    timeout_min: 10\n",
       "    cpus_per_task: 1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Code(filename=\"hydra_tutorial/configs/cluster/slurm.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run! Here, we overwrite the launcher with the local version to test it, because we don't have a cluster at hand right now.\n",
    "For this we append `hydra/launcher=submitit_local`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2023-11-28 10:09:25,384\u001b[0m][\u001b[35mHYDRA\u001b[0m] Submitit 'local' sweep output dir : runs/2023-11-28/10-09-24\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:25,385\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#0 : hidden_layer_sizes=[100] seed=1 +cluster=slurm\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:25,392\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#1 : hidden_layer_sizes=[100] seed=2 +cluster=slurm\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:25,396\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#2 : hidden_layer_sizes=[100] seed=3 +cluster=slurm\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:25,399\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#3 : hidden_layer_sizes=[100] seed=4 +cluster=slurm\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:25,403\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#4 : hidden_layer_sizes=[100] seed=5 +cluster=slurm\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:25,409\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#5 : hidden_layer_sizes=[10,10,10] seed=1 +cluster=slurm\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:25,413\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#6 : hidden_layer_sizes=[10,10,10] seed=2 +cluster=slurm\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:25,416\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#7 : hidden_layer_sizes=[10,10,10] seed=3 +cluster=slurm\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:25,420\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#8 : hidden_layer_sizes=[10,10,10] seed=4 +cluster=slurm\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:09:25,424\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#9 : hidden_layer_sizes=[10,10,10] seed=5 +cluster=slurm\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline.py', 'hidden_layer_sizes=[100],[10,10,10]', 'seed=range(1,6)', '+cluster=slurm', 'hydra/launcher=submitit_local', '-m'], returncode=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\n",
    "    \"python hydra_tutorial/classic_pipeline.py hidden_layer_sizes=[100],[10,10,10] seed=range(1,6) +cluster=slurm hydra/launcher=submitit_local -m\".split(\n",
    "        \" \"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composition\n",
    "A great feature of hydra is that you can compose your configuration with different config files. We already did this with the cluster config, but here we do it more explicitly.\n",
    "This comes especially in handy if we want to configure different modules and experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.9343\n",
      "[\u001b[36m2023-11-28 10:10:27,480\u001b[0m][\u001b[35mHYDRA\u001b[0m] Joblib.Parallel(n_jobs=-1,backend=loky,prefer=processes,require=None,verbose=0,timeout=None,pre_dispatch=2*n_jobs,batch_size=auto,temp_folder=None,max_nbytes=None,mmap_mode=r) is launching 3 jobs\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:10:27,480\u001b[0m][\u001b[35mHYDRA\u001b[0m] Launching jobs, sweep output dir : runs/2023-11-28/10-10-27\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:10:27,480\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#0 : +architecture=big_mlp +solver=adam\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:10:27,480\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#1 : +architecture=medium_mlp +solver=adam\u001b[0m\n",
      "[\u001b[36m2023-11-28 10:10:27,481\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#2 : +architecture=tiny_mlp +solver=adam\u001b[0m\n",
      "Mean accuracy: 0.9343\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline.py', \"+architecture=glob('*')\", '+solver=adam', '-m'], returncode=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One composition\n",
    "subprocess.run(\"python hydra_tutorial/classic_pipeline.py +architecture=tiny_mlp +solver=adam\".split(\" \"))\n",
    "\n",
    "# Sweep over all in one folder\n",
    "subprocess.run(\"python hydra_tutorial/classic_pipeline.py +architecture=glob('*') +solver=adam -m\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "Hydra can also instantiate classes from config files, either fully or partially. \n",
    "This means you have full flexibility of configuring your project!\n",
    "\n",
    "Check the docs here: https://hydra.cc/docs/advanced/instantiate_objects/overview/\n",
    "\n",
    "Small example here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'hydra_tutorial.some_class.MyClass'</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'hydra_tutorial.some_class.MyClass'\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">hydra_tutorial.some_class.MyClass</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f6a0e2b7810</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mhydra_tutorial.some_class.MyClass\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7f6a0e2b7810\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">hydra_tutorial.some_class.MyClass</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f6a0df2bb10</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mhydra_tutorial.some_class.MyClass\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7f6a0df2bb10\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34555\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">functools.partial</span><span style=\"font-weight: bold\">(&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'hydra_tutorial.some_class.MyClass'</span><span style=\"font-weight: bold\">&gt;</span>, <span style=\"color: #808000; text-decoration-color: #808000\">my_number</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34555</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mfunctools.partial\u001b[0m\u001b[1m(\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'hydra_tutorial.some_class.MyClass'\u001b[0m\u001b[1m>\u001b[0m, \u001b[33mmy_number\u001b[0m=\u001b[1;36m34555\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34555\n"
     ]
    }
   ],
   "source": [
    "from rich import print as printr\n",
    "from omegaconf import DictConfig\n",
    "from hydra.utils import get_class, instantiate\n",
    "\n",
    "# We have a custom class in `some_class.py` which we want to specify\n",
    "# via the config files. Then we can just specify in the yaml: `myclass: hydra_tutorial.some_class.MyClass`\n",
    "# Hydra will automatically instantiate (partially) your class and you have it ready in your config!\n",
    "# This is super handy if you want to sweep classes.\n",
    "\n",
    "# Example 1: Let's just get the class\n",
    "class_str = \"hydra_tutorial.some_class.MyClass\" \n",
    "my_custom_class_cls = get_class(class_str)\n",
    "printr(my_custom_class_cls)\n",
    "\n",
    "# Example 2: Let's already instatiate the class\n",
    "cfg = DictConfig({\"_target_\": class_str})\n",
    "my_custom_class = instantiate(config=cfg)\n",
    "printr(my_custom_class)\n",
    "my_custom_class.show_my_number()\n",
    "\n",
    "# Example 3: Let's instantiate and configure the class\n",
    "cfg = DictConfig({\"_target_\": class_str, \"my_number\": 34555})\n",
    "my_custom_class = instantiate(config=cfg)\n",
    "printr(my_custom_class)\n",
    "my_custom_class.show_my_number()\n",
    "\n",
    "# Example 4: Let's instantiate and configure the class, BUT PARTIALLY\n",
    "cfg = DictConfig({\"_target_\": class_str, \"_partial_\": True, \"my_number\": 34555})\n",
    "my_custom_class_cls = instantiate(config=cfg)\n",
    "printr(my_custom_class_cls)\n",
    "my_custom_class_cls().show_my_number() # now instantiate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n",
    "We can not only run configurations in parallel, we can also do proper HPO with hydra with suitable plugins.\n",
    "Available sweepers are:\n",
    "- [Ax](https://hydra.cc/docs/plugins/ax_sweeper/)\n",
    "- [Optuna](https://hydra.cc/docs/plugins/nevergrad_sweeper/)\n",
    "- [Nevergrad](https://hydra.cc/docs/plugins/optuna_sweeper/)\n",
    "\n",
    "In addition, we are happy to announce the first alpha version of the [Hydra-SMAC-Sweeper](https://github.com/automl/hydra-smac-sweeper)! ü•≥\n",
    "We have created an interface between hydra and [SMAC3](https://github.com/automl/SMAC3).\n",
    "Make sure you installed everything via `bash install.sh`. üôÇ\n",
    "\n",
    "PS: Check the dask dashboard at http://localhost:8787/status üìä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config \u001b[1m{\u001b[0m\u001b[32m'hydra'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'run'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'dir'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32moutdir\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'sweep'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'dir'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32moutdir\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \n",
      "\u001b[32m'subdir'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mhydra.job.num\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'launcher'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'_target_'\u001b[0m: \n",
      "\u001b[32m'hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher'\u001b[0m, \u001b[32m'n_jobs'\u001b[0m: \n",
      "\u001b[1;36m-1\u001b[0m, \u001b[32m'backend'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'prefer'\u001b[0m: \u001b[32m'processes'\u001b[0m, \u001b[32m'require'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'verbose'\u001b[0m: \u001b[1;36m0\u001b[0m, \n",
      "\u001b[32m'timeout'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'pre_dispatch'\u001b[0m: \u001b[32m'2*n_jobs'\u001b[0m, \u001b[32m'batch_size'\u001b[0m: \u001b[32m'auto'\u001b[0m, \n",
      "\u001b[32m'temp_folder'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'max_nbytes'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'mmap_mode'\u001b[0m: \u001b[32m'r'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'sweeper'\u001b[0m: \n",
      "\u001b[1m{\u001b[0m\u001b[32m'_target_'\u001b[0m: \u001b[32m'hydra_plugins.hydra_smac_sweeper.smac_sweeper.SMACSweeper'\u001b[0m, \n",
      "\u001b[32m'search_space'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'hyperparameters'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'alpha'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'uniform_float'\u001b[0m, \u001b[32m'lower'\u001b[0m:\n",
      "\u001b[1;36m1e-06\u001b[0m, \u001b[32m'upper'\u001b[0m: \u001b[1;36m0.01\u001b[0m, \u001b[32m'log'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'default_value'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32malpha\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'solver'\u001b[0m: \n",
      "\u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'categorical'\u001b[0m, \u001b[32m'choices'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'lbfgs'\u001b[0m, \u001b[32m'adam'\u001b[0m, \u001b[32m'sgd'\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'default_value'\u001b[0m: \n",
      "\u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32msolver\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'activation'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'categorical'\u001b[0m, \u001b[32m'choices'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'logistic'\u001b[0m, \n",
      "\u001b[32m'tanh'\u001b[0m, \u001b[32m'relu'\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'default_value'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mactivation\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'scenario'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'seed'\u001b[0m: \n",
      "\u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mseed\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'n_trials'\u001b[0m: \u001b[1;36m100\u001b[0m, \u001b[32m'deterministic'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'n_workers'\u001b[0m: \u001b[1;36m4\u001b[0m\u001b[1m}\u001b[0m, \n",
      "\u001b[32m'smac_class'\u001b[0m: \u001b[32m'smac.facade.blackbox_facade.BlackBoxFacade'\u001b[0m, \u001b[32m'smac_kwargs'\u001b[0m: \n",
      "\u001b[1m{\u001b[0m\u001b[32m'dask_client'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'logging_level'\u001b[0m: \u001b[1;36m20\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'help'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'app_name'\u001b[0m: \n",
      "\u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mhydra.job.name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'header'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mhydra.help.app_name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m is powered by Hydra.\\n'\u001b[0m, \n",
      "\u001b[32m'footer'\u001b[0m: \u001b[32m'Powered by Hydra \u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://hydra.cc\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nUse --hydra-help to view Hydra \u001b[0m\n",
      "\u001b[32mspecific help\\n'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mhydra.help.header\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\u001b[0m\u001b[32mn\u001b[0m\u001b[32m== Configuration groups \u001b[0m\n",
      "\u001b[32m==\\nCompose your configuration from those groups \u001b[0m\n",
      "\u001b[32m(\u001b[0m\u001b[32mgroup\u001b[0m\u001b[32m=\u001b[0m\u001b[32moption\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n$APP_CONFIG_GROUPS\\n\\\u001b[0m\u001b[32mn\u001b[0m\u001b[32m== Config ==\\nOverride anything in the \u001b[0m\n",
      "\u001b[32mconfig \u001b[0m\u001b[32m(\u001b[0m\u001b[32mfoo.\u001b[0m\u001b[32mbar\u001b[0m\u001b[32m=\u001b[0m\u001b[32mvalue\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n$CONFIG\\n\\n$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mhydra.help.footer\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'hydra_help'\u001b[0m: \n",
      "\u001b[1m{\u001b[0m\u001b[32m'template'\u001b[0m: \u001b[32m\"Hydra \u001b[0m\u001b[32m(\u001b[0m\u001b[32m$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mhydra.runtime.version\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nSee https://hydra.cc for more \u001b[0m\n",
      "\u001b[32minfo.\\n\\\u001b[0m\u001b[32mn\u001b[0m\u001b[32m== Flags ==\\n$FLAGS_HELP\\n\\\u001b[0m\u001b[32mn\u001b[0m\u001b[32m== Configuration groups ==\\nCompose your \u001b[0m\n",
      "\u001b[32mconfiguration from those groups \u001b[0m\u001b[32m(\u001b[0m\u001b[32mFor example, append hydra/\u001b[0m\u001b[32mjob_logging\u001b[0m\u001b[32m=\u001b[0m\u001b[32mdisabled\u001b[0m\u001b[32m \u001b[0m\n",
      "\u001b[32mto command line\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n$HYDRA_CONFIG_GROUPS\\n\\nUse '--cfg hydra' to Show the Hydra \u001b[0m\n",
      "\u001b[32mconfig.\\n\"\u001b[0m, \u001b[32m'hydra_help'\u001b[0m: \u001b[32m'???'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'hydra_logging'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'version'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'formatters'\u001b[0m: \n",
      "\u001b[1m{\u001b[0m\u001b[32m'colorlog'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[32m'colorlog.ColoredFormatter'\u001b[0m, \u001b[32m'format'\u001b[0m: \n",
      "\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcyan\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms%\u001b[0m\u001b[32m(\u001b[0m\u001b[32masctime\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mreset\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms\u001b[0m\u001b[32m]\u001b[0m\u001b[32m[\u001b[0m\u001b[32m%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mpurple\u001b[0m\u001b[32m)\u001b[0m\u001b[32msHYDRA%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mreset\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms\u001b[0m\u001b[32m]\u001b[0m\u001b[32m %\u001b[0m\u001b[32m(\u001b[0m\u001b[32mmessage\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \n",
      "\u001b[32m'handlers'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'console'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'class'\u001b[0m: \u001b[32m'logging.StreamHandler'\u001b[0m, \u001b[32m'formatter'\u001b[0m: \n",
      "\u001b[32m'colorlog'\u001b[0m, \u001b[32m'stream'\u001b[0m: \u001b[32m'ext://sys.stdout'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'root'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'level'\u001b[0m: \u001b[32m'INFO'\u001b[0m, \n",
      "\u001b[32m'handlers'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'console'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'disable_existing_loggers'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'job_logging'\u001b[0m: \n",
      "\u001b[1m{\u001b[0m\u001b[32m'version'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'formatters'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'simple'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'format'\u001b[0m: \n",
      "\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m%\u001b[0m\u001b[32m(\u001b[0m\u001b[32masctime\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms\u001b[0m\u001b[32m]\u001b[0m\u001b[32m[\u001b[0m\u001b[32m%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mname\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms\u001b[0m\u001b[32m]\u001b[0m\u001b[32m[\u001b[0m\u001b[32m%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mlevelname\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms\u001b[0m\u001b[32m]\u001b[0m\u001b[32m - %\u001b[0m\u001b[32m(\u001b[0m\u001b[32mmessage\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'colorlog'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \n",
      "\u001b[32m'colorlog.ColoredFormatter'\u001b[0m, \u001b[32m'format'\u001b[0m: \n",
      "\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcyan\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms%\u001b[0m\u001b[32m(\u001b[0m\u001b[32masctime\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mreset\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms\u001b[0m\u001b[32m]\u001b[0m\u001b[32m[\u001b[0m\u001b[32m%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mblue\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mname\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mreset\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms\u001b[0m\u001b[32m]\u001b[0m\u001b[32m[\u001b[0m\u001b[32m%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mlog_color\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mleveln\u001b[0m\n",
      "\u001b[32mame\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mreset\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms\u001b[0m\u001b[32m]\u001b[0m\u001b[32m - %\u001b[0m\u001b[32m(\u001b[0m\u001b[32mmessage\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms'\u001b[0m, \u001b[32m'log_colors'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'DEBUG'\u001b[0m: \u001b[32m'purple'\u001b[0m, \u001b[32m'INFO'\u001b[0m: \n",
      "\u001b[32m'green'\u001b[0m, \u001b[32m'WARNING'\u001b[0m: \u001b[32m'yellow'\u001b[0m, \u001b[32m'ERROR'\u001b[0m: \u001b[32m'red'\u001b[0m, \u001b[32m'CRITICAL'\u001b[0m: \u001b[32m'red'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'handlers'\u001b[0m: \n",
      "\u001b[1m{\u001b[0m\u001b[32m'console'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'class'\u001b[0m: \u001b[32m'logging.StreamHandler'\u001b[0m, \u001b[32m'formatter'\u001b[0m: \u001b[32m'colorlog'\u001b[0m, \n",
      "\u001b[32m'stream'\u001b[0m: \u001b[32m'ext://sys.stdout'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'file'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'class'\u001b[0m: \u001b[32m'logging.FileHandler'\u001b[0m, \n",
      "\u001b[32m'formatter'\u001b[0m: \u001b[32m'simple'\u001b[0m, \u001b[32m'filename'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mhydra.job.name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m.log'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'root'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'level'\u001b[0m: \n",
      "\u001b[32m'INFO'\u001b[0m, \u001b[32m'handlers'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'console'\u001b[0m, \u001b[32m'file'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'disable_existing_loggers'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m, \n",
      "\u001b[32m'env'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'mode'\u001b[0m: \u001b[1m<\u001b[0m\u001b[1;95mRunMode.MULTIRUN:\u001b[0m\u001b[39m \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m>\u001b[0m, \u001b[32m'searchpath'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'callbacks'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \n",
      "\u001b[32m'output_subdir'\u001b[0m: \u001b[32m'.hydra'\u001b[0m, \u001b[32m'overrides'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'hydra'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'hydra.\u001b[0m\u001b[32mmode\u001b[0m\u001b[32m=\u001b[0m\u001b[32mMULTIRUN\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m, \n",
      "\u001b[32m'task'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'+\u001b[0m\u001b[32mhpo\u001b[0m\u001b[32m=\u001b[0m\u001b[32msmac\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'job'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'classic_pipeline'\u001b[0m, \u001b[32m'chdir'\u001b[0m: \u001b[3;35mNone\u001b[0m, \n",
      "\u001b[32m'override_dirname'\u001b[0m: \u001b[32m'+\u001b[0m\u001b[32mhpo\u001b[0m\u001b[32m=\u001b[0m\u001b[32msmac\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'id'\u001b[0m: \u001b[32m'???'\u001b[0m, \u001b[32m'num'\u001b[0m: \u001b[32m'???'\u001b[0m, \u001b[32m'config_name'\u001b[0m: \n",
      "\u001b[32m'base'\u001b[0m, \u001b[32m'env_set'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'env_copy'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'config'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'override_dirname'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'kv_sep'\u001b[0m:\n",
      "\u001b[32m'='\u001b[0m, \u001b[32m'item_sep'\u001b[0m: \u001b[32m','\u001b[0m, \u001b[32m'exclude_keys'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'runtime'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'version'\u001b[0m: \u001b[32m'1.3.2'\u001b[0m, \n",
      "\u001b[32m'version_base'\u001b[0m: \u001b[32m'1.3'\u001b[0m, \u001b[32m'cwd'\u001b[0m: \u001b[32m'/home/numina/Documents/repos/hydra_tutorial'\u001b[0m, \n",
      "\u001b[32m'config_sources'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'path'\u001b[0m: \u001b[32m'hydra.conf'\u001b[0m, \u001b[32m'schema'\u001b[0m: \u001b[32m'pkg'\u001b[0m, \u001b[32m'provider'\u001b[0m: \u001b[32m'hydra'\u001b[0m\u001b[1m}\u001b[0m,\n",
      "\u001b[1m{\u001b[0m\u001b[32m'path'\u001b[0m: \u001b[32m'/home/numina/Documents/repos/hydra_tutorial/hydra_tutorial/configs'\u001b[0m, \n",
      "\u001b[32m'schema'\u001b[0m: \u001b[32m'file'\u001b[0m, \u001b[32m'provider'\u001b[0m: \u001b[32m'main'\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'path'\u001b[0m: \n",
      "\u001b[32m'hydra_plugins.hydra_colorlog.conf'\u001b[0m, \u001b[32m'schema'\u001b[0m: \u001b[32m'pkg'\u001b[0m, \u001b[32m'provider'\u001b[0m: \n",
      "\u001b[32m'hydra-colorlog'\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'path'\u001b[0m: \u001b[32m''\u001b[0m, \u001b[32m'schema'\u001b[0m: \u001b[32m'structured'\u001b[0m, \u001b[32m'provider'\u001b[0m: \u001b[32m'schema'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m, \n",
      "\u001b[32m'output_dir'\u001b[0m: \u001b[32m'???'\u001b[0m, \u001b[32m'choices'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'hpo'\u001b[0m: \u001b[32m'smac'\u001b[0m, \u001b[32m'hydra/env'\u001b[0m: \u001b[32m'default'\u001b[0m, \n",
      "\u001b[32m'hydra/callbacks'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'hydra/job_logging'\u001b[0m: \u001b[32m'colorlog'\u001b[0m, \u001b[32m'hydra/hydra_logging'\u001b[0m:\n",
      "\u001b[32m'colorlog'\u001b[0m, \u001b[32m'hydra/hydra_help'\u001b[0m: \u001b[32m'default'\u001b[0m, \u001b[32m'hydra/help'\u001b[0m: \u001b[32m'default'\u001b[0m, \n",
      "\u001b[32m'hydra/sweeper'\u001b[0m: \u001b[32m'SMAC'\u001b[0m, \u001b[32m'hydra/launcher'\u001b[0m: \u001b[32m'joblib'\u001b[0m, \u001b[32m'hydra/output'\u001b[0m: \n",
      "\u001b[32m'default'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'verbose'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'seed'\u001b[0m: \u001b[1;36m1234\u001b[0m, \u001b[32m'hidden_layer_sizes'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1m]\u001b[0m, \n",
      "\u001b[32m'max_iter'\u001b[0m: \u001b[1;36m100\u001b[0m, \u001b[32m'activation'\u001b[0m: \u001b[32m'relu'\u001b[0m, \u001b[32m'solver'\u001b[0m: \u001b[32m'adam'\u001b[0m, \u001b[32m'alpha'\u001b[0m: \u001b[1;36m0.0001\u001b[0m, \n",
      "\u001b[32m'outdir'\u001b[0m: \u001b[32m'runs/$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mnow:%Y-%m-%d\u001b[0m\u001b[32m}\u001b[0m\u001b[32m/$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mnow:%H-%M-%S\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m\n",
      "Hydra context\n",
      "\u001b[1;35mHydraContext\u001b[0m\u001b[1m(\u001b[0m\n",
      "    \u001b[33mconfig_loader\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mhydra._internal.config_loader_impl.ConfigLoaderImpl\u001b[0m\u001b[39m object at\u001b[0m\n",
      "\u001b[1;36m0x7f638fd82650\u001b[0m\u001b[39m>,\u001b[0m\n",
      "\u001b[39m    \u001b[0m\u001b[33mcallbacks\u001b[0m\u001b[39m=<hydra._internal.callbacks.Callbacks object at \u001b[0m\u001b[1;36m0x7f638fc21810\u001b[0m\u001b[1m>\u001b[0m\n",
      "\u001b[1m)\u001b[0m\n",
      "Launcher \u001b[1m<\u001b[0m\u001b[1;95mhydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher\u001b[0m\u001b[39m \u001b[0m\n",
      "\u001b[39mobject at \u001b[0m\u001b[1;36m0x7f638fc729d0\u001b[0m\u001b[1m>\u001b[0m\n",
      "\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'smac.facade.blackbox_facade.BlackBoxFacade'\u001b[0m\u001b[1m>\u001b[0m\n",
      "\u001b[1m{\u001b[0m\n",
      "    \u001b[32m'dask_client'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "    \u001b[32m'logging_level'\u001b[0m: \u001b[1;36m20\u001b[0m,\n",
      "    \u001b[32m'scenario'\u001b[0m: \u001b[1;35mScenario\u001b[0m\u001b[1m(\u001b[0m\n",
      "        \u001b[33mconfigspace\u001b[0m=\u001b[35mConfiguration\u001b[0m space object:\n",
      "  Hyperparameters:\n",
      "    activation, Type: Categorical, Choices: \u001b[1m{\u001b[0mlogistic, tanh, relu\u001b[1m}\u001b[0m, Default: \n",
      "logistic\n",
      "    alpha, Type: UniformFloat, Range: \u001b[1m[\u001b[0m\u001b[1;36m1e-06\u001b[0m, \u001b[1;36m0.01\u001b[0m\u001b[1m]\u001b[0m, Default: \u001b[1;36m0.0001\u001b[0m, on \n",
      "log-scale\n",
      "    solver, Type: Categorical, Choices: \u001b[1m{\u001b[0mlbfgs, adam, sgd\u001b[1m}\u001b[0m, Default: lbfgs\n",
      ",\n",
      "        \u001b[33mname\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "        \u001b[33moutput_directory\u001b[0m=\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'runs/2023-11-28/10-10-37/smac3_output'\u001b[0m\u001b[1m)\u001b[0m,\n",
      "        \u001b[33mdeterministic\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
      "        \u001b[33mobjectives\u001b[0m=\u001b[32m'cost'\u001b[0m,\n",
      "        \u001b[33mcrash_cost\u001b[0m=\u001b[35minf\u001b[0m,\n",
      "        \u001b[33mtermination_cost_threshold\u001b[0m=\u001b[35minf\u001b[0m,\n",
      "        \u001b[33mwalltime_limit\u001b[0m=\u001b[35minf\u001b[0m,\n",
      "        \u001b[33mcputime_limit\u001b[0m=\u001b[35minf\u001b[0m,\n",
      "        \u001b[33mtrial_walltime_limit\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "        \u001b[33mtrial_memory_limit\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "        \u001b[33mn_trials\u001b[0m=\u001b[1;36m100\u001b[0m,\n",
      "        \u001b[33muse_default_config\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
      "        \u001b[33minstances\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "        \u001b[33minstance_features\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "        \u001b[33mmin_budget\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "        \u001b[33mmax_budget\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "        \u001b[33mseed\u001b[0m=\u001b[1;36m1234\u001b[0m,\n",
      "        \u001b[33mn_workers\u001b[0m=\u001b[1;36m4\u001b[0m\n",
      "    \u001b[1m)\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "[WARNING][target_function_runner.py:72] The argument budget is not set by SMAC: Consider removing it from the target function.\n",
      "[WARNING][target_function_runner.py:72] The argument instance is not set by SMAC: Consider removing it from the target function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/numina/Documents/repos/hydra_tutorial/hydra-smac-sweeper/hydra_plugins/hydra_smac_sweeper/smac_sweeper_backend.py:291: UserWarning: Override arguments might not have an effect if they are a sweep. ['+hpo=smac']\n",
      "  warnings.warn(f\"Override arguments might not have an effect if they are a sweep. {arguments}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_initial_design.py:147] Using 24 initial design configurations and 0 additional configurations.\n",
      "[INFO][abstract_intensifier.py:305] Using only one seed for deterministic scenario.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "Mean accuracy: 0.9468\n",
      "[INFO][abstract_intensifier.py:515] Added config 61c487 as new incumbent because there are no incumbents yet.\n",
      "Mean accuracy: 0.9584\n",
      "[INFO][abstract_intensifier.py:590] Added config 1d50b9 and rejected config 61c487 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "Mean accuracy: 0.9127\n",
      "Mean accuracy: 0.9617\n",
      "Mean accuracy: 0.9559\n",
      "[INFO][abstract_intensifier.py:590] Added config f46e63 and rejected config 1d50b9 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "Mean accuracy: 0.9634\n",
      "[INFO][abstract_intensifier.py:590] Added config 531091 and rejected config f46e63 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "Mean accuracy: 0.9592\n",
      "Mean accuracy: 0.9343\n",
      "Mean accuracy: 0.9343\n",
      "Mean accuracy: 0.9451\n",
      "Mean accuracy: 0.9617\n",
      "Mean accuracy: 0.9534\n",
      "Mean accuracy: 0.9493\n",
      "Mean accuracy: 0.9518\n",
      "Mean accuracy: 0.9493\n",
      "Mean accuracy: 0.9592\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9343\n",
      "Mean accuracy: 0.9559\n",
      "Mean accuracy: 0.9127\n",
      "Mean accuracy: 0.9509\n",
      "Mean accuracy: 0.9592\n",
      "Mean accuracy: 0.9127\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9509\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9592\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9509\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9593\n",
      "Mean accuracy: 0.9127\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9601\n",
      "Mean accuracy: 0.9593\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9568\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9617\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: inf\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 0\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9617\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "[INFO][smbo.py:592] \n",
      "--- STATISTICS -------------------------------------\n",
      "--- Incumbent changed: 4\n",
      "--- Submitted trials: 100 / 100\n",
      "--- Finished trials: 100 / 100\n",
      "--- Configurations: 100\n",
      "--- Used wallclock time: 133 / inf sec\n",
      "--- Used target function runtime: 494.29 / inf sec\n",
      "----------------------------------------------------\n",
      "[INFO][smac_sweeper_backend.py:299] Final Incumbent: Configuration(values={\n",
      "  'activation': 'logistic',\n",
      "  'alpha': 0.0007911530994138094,\n",
      "  'solver': 'adam',\n",
      "})\n",
      "[INFO][smac_sweeper_backend.py:302] Estimated cost of incumbent: 0.036576763485477115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline.py', '+hpo=smac', '-m'], returncode=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\"python hydra_tutorial/classic_pipeline.py +hpo=smac -m\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "1. parametrizable function, (hyper)parameters as DictConfig\n",
    "2. hydra decorates, configuration file\n",
    "3. introduce override syntax commandline\n",
    "4. introduce sweeps (e.g. multiple seeds), sequential\n",
    "5. introduce launchers (local: joblib, but also slurm/submitit)\n",
    "6. introduce composition\n",
    "7. introduce instantiation\n",
    "8. hyperparameter optimization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
