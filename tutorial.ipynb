{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure\n",
    "1. classic pipeline, params hardcoded everywhere\n",
    "2. parametrizable function, introduce DictConfig\n",
    "3. hydra decorates, introduce configuration file\n",
    "4. introduce override syntax commandline\n",
    "5. introduce sweeps (e.g. multiple seeds), sequential\n",
    "6. introduce launchers (local: joblib, but also slurm/submitit)\n",
    "7. introduce composition\n",
    "8. introduce instantiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML Fall School 2023 Hydra Hands-On\n",
    "\n",
    "Welcome to our tutorial session on [hydra](hydra.cc)! üêç\n",
    "Hydra is a tool for configuring and running your experiments and optimization is seemlessly integrated.\n",
    "\n",
    "Hydra can:\n",
    "\n",
    "* Hierarchical configuration composable from multiple sources\n",
    "* Configuration can be specified or overridden from the command line\n",
    "* Dynamic command line tab completion\n",
    "* Run your application locally or launch it to run remotely\n",
    "* Run multiple jobs with different arguments with a single command\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Classical Training Pipeline\n",
    "\n",
    "(This part of the tutorial is the same as in the SMAC tutorial).\n",
    "\n",
    "We'll start with your classical optimization task.\n",
    "The task is to optimize the hyperparameters of a [sklearn.neural_network.MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) on the [digits](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) dataset. Usually we have some training pipeline with a dataset, a configured model[^1] and some validation procedure to check for generalization performance like this:\n",
    "\n",
    "\n",
    "[^1]: If we check out the documentation, we will see that loads of design decisions (hyperparameters) are already set to a default value for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn</span> <span class=\"kn\">import</span> <span class=\"n\">datasets</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.neural_network</span> <span class=\"kn\">import</span> <span class=\"n\">MLPClassifier</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">cross_val_score</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">ConvergenceWarning</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">warnings</span>\n",
       "<span class=\"n\">warnings</span><span class=\"o\">.</span><span class=\"n\">filterwarnings</span><span class=\"p\">(</span><span class=\"s2\">&quot;ignore&quot;</span><span class=\"p\">,</span> <span class=\"n\">category</span><span class=\"o\">=</span><span class=\"n\">ConvergenceWarning</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># We load the digits dataset</span>\n",
       "<span class=\"n\">digits</span> <span class=\"o\">=</span> <span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">load_digits</span><span class=\"p\">()</span>\n",
       "<span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">digits</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">digits</span><span class=\"o\">.</span><span class=\"n\">target</span>\n",
       "\n",
       "<span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">X_test</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">y_test</span> <span class=\"o\">=</span> <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">test_size</span><span class=\"o\">=</span><span class=\"mf\">0.33</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">train_mlp</span><span class=\"p\">()</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">float</span><span class=\"p\">:</span>\n",
       "    <span class=\"c1\"># we want to have reproducible training</span>\n",
       "    <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"mi\">1234</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># for illustrative purposes, you can reduce max_iter drastically here</span>\n",
       "    <span class=\"n\">classifier</span> <span class=\"o\">=</span> <span class=\"n\">MLPClassifier</span><span class=\"p\">(</span><span class=\"n\">hidden_layer_sizes</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,),</span> <span class=\"n\">max_iter</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">,</span> <span class=\"n\">solver</span><span class=\"o\">=</span><span class=\"s1\">&#39;adam&#39;</span><span class=\"p\">)</span>\n",
       "    <span class=\"n\">scores</span> <span class=\"o\">=</span> <span class=\"n\">cross_val_score</span><span class=\"p\">(</span><span class=\"n\">classifier</span><span class=\"p\">,</span> <span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">cv</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">return</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">scores</span><span class=\"p\">)</span> <span class=\"c1\"># mean accuracy over folds</span>\n",
       "\n",
       "<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;__main__&quot;</span><span class=\"p\">:</span>\n",
       "    <span class=\"c1\"># Ignore the warnings for now:)</span>\n",
       "    <span class=\"n\">cv_loss</span> <span class=\"o\">=</span> <span class=\"n\">train_mlp</span><span class=\"p\">()</span>\n",
       "    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">&#39;Cross_validation accuaracy on digits </span><span class=\"si\">{</span><span class=\"n\">cv_loss</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn} \\PY{k+kn}{import} \\PY{n}{datasets}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{neural\\PYZus{}network} \\PY{k+kn}{import} \\PY{n}{MLPClassifier}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{cross\\PYZus{}val\\PYZus{}score}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{exceptions} \\PY{k+kn}{import} \\PY{n}{ConvergenceWarning}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{warnings}\n",
       "\\PY{n}{warnings}\\PY{o}{.}\\PY{n}{filterwarnings}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{ignore}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{category}\\PY{o}{=}\\PY{n}{ConvergenceWarning}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} We load the digits dataset}\n",
       "\\PY{n}{digits} \\PY{o}{=} \\PY{n}{datasets}\\PY{o}{.}\\PY{n}{load\\PYZus{}digits}\\PY{p}{(}\\PY{p}{)}\n",
       "\\PY{n}{X}\\PY{p}{,} \\PY{n}{y} \\PY{o}{=} \\PY{n}{digits}\\PY{o}{.}\\PY{n}{data}\\PY{p}{,} \\PY{n}{digits}\\PY{o}{.}\\PY{n}{target}\n",
       "\n",
       "\\PY{n}{X\\PYZus{}train}\\PY{p}{,} \\PY{n}{X\\PYZus{}test}\\PY{p}{,} \\PY{n}{y\\PYZus{}train}\\PY{p}{,} \\PY{n}{y\\PYZus{}test} \\PY{o}{=} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\\PY{p}{(}\\PY{n}{X}\\PY{p}{,} \\PY{n}{y}\\PY{p}{,} \\PY{n}{test\\PYZus{}size}\\PY{o}{=}\\PY{l+m+mf}{0.33}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{train\\PYZus{}mlp}\\PY{p}{(}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n+nb}{float}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} we want to have reproducible training}\n",
       "    \\PY{n}{np}\\PY{o}{.}\\PY{n}{random}\\PY{o}{.}\\PY{n}{seed}\\PY{p}{(}\\PY{n}{seed}\\PY{o}{=}\\PY{l+m+mi}{1234}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} for illustrative purposes, you can reduce max\\PYZus{}iter drastically here}\n",
       "    \\PY{n}{classifier} \\PY{o}{=} \\PY{n}{MLPClassifier}\\PY{p}{(}\\PY{n}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{o}{=}\\PY{p}{(}\\PY{l+m+mi}{100}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{max\\PYZus{}iter}\\PY{o}{=}\\PY{l+m+mi}{100}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{relu}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{solver}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{adam}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "    \\PY{n}{scores} \\PY{o}{=} \\PY{n}{cross\\PYZus{}val\\PYZus{}score}\\PY{p}{(}\\PY{n}{classifier}\\PY{p}{,} \\PY{n}{X\\PYZus{}train}\\PY{p}{,} \\PY{n}{y\\PYZus{}train}\\PY{p}{,} \\PY{n}{cv}\\PY{o}{=}\\PY{l+m+mi}{5}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{return} \\PY{n}{np}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{n}{scores}\\PY{p}{)} \\PY{c+c1}{\\PYZsh{} mean accuracy over folds}\n",
       "\n",
       "\\PY{k}{if} \\PY{n+nv+vm}{\\PYZus{}\\PYZus{}name\\PYZus{}\\PYZus{}} \\PY{o}{==} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZus{}\\PYZus{}main\\PYZus{}\\PYZus{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} Ignore the warnings for now:)}\n",
       "    \\PY{n}{cv\\PYZus{}loss} \\PY{o}{=} \\PY{n}{train\\PYZus{}mlp}\\PY{p}{(}\\PY{p}{)}\n",
       "    \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Cross\\PYZus{}validation accuaracy on digits }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{cv\\PYZus{}loss}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn import datasets\n",
       "from sklearn.neural_network import MLPClassifier\n",
       "from sklearn.model_selection import cross_val_score\n",
       "import numpy as np\n",
       "from sklearn.exceptions import ConvergenceWarning\n",
       "import warnings\n",
       "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
       "\n",
       "# We load the digits dataset\n",
       "digits = datasets.load_digits()\n",
       "X, y = digits.data, digits.target\n",
       "\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
       "\n",
       "def train_mlp() -> float:\n",
       "    # we want to have reproducible training\n",
       "    np.random.seed(seed=1234)\n",
       "\n",
       "    # for illustrative purposes, you can reduce max_iter drastically here\n",
       "    classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=100, activation='relu', solver='adam')\n",
       "    scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
       "\n",
       "    return np.mean(scores) # mean accuracy over folds\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    # Ignore the warnings for now:)\n",
       "    cv_loss = train_mlp()\n",
       "    print(f'Cross_validation accuaracy on digits {cv_loss}')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Code\n",
    "Code(filename=\"hydra_tutorial/classic_pipeline_hardcoded.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_validation accuaracy on digits 0.9625795297372062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline_hardcoded.py'], returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run(\"python hydra_tutorial/classic_pipeline_hardcoded.py\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You can ignore the errors above regarding not converging for now.\n",
    "\n",
    "What we can see in this example is that we hardcoded many (hyper-)parameters. But maybe we would like to vary them? So let's adapt our `train_mlp` function!\n",
    "We will use a dict-like object to hold all our parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn</span> <span class=\"kn\">import</span> <span class=\"n\">datasets</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.neural_network</span> <span class=\"kn\">import</span> <span class=\"n\">MLPClassifier</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">cross_val_score</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">omegaconf</span> <span class=\"kn\">import</span> <span class=\"n\">DictConfig</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">rich</span> <span class=\"kn\">import</span> <span class=\"nb\">print</span> <span class=\"k\">as</span> <span class=\"n\">printr</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">rich</span> <span class=\"kn\">import</span> <span class=\"n\">inspect</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">ConvergenceWarning</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">warnings</span>\n",
       "<span class=\"n\">warnings</span><span class=\"o\">.</span><span class=\"n\">filterwarnings</span><span class=\"p\">(</span><span class=\"s2\">&quot;ignore&quot;</span><span class=\"p\">,</span> <span class=\"n\">category</span><span class=\"o\">=</span><span class=\"n\">ConvergenceWarning</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># We load the digits dataset</span>\n",
       "<span class=\"n\">digits</span> <span class=\"o\">=</span> <span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">load_digits</span><span class=\"p\">()</span>\n",
       "<span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">digits</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">digits</span><span class=\"o\">.</span><span class=\"n\">target</span>\n",
       "\n",
       "<span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">X_test</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">y_test</span> <span class=\"o\">=</span> <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">test_size</span><span class=\"o\">=</span><span class=\"mf\">0.33</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">train_mlp</span><span class=\"p\">(</span><span class=\"n\">cfg</span><span class=\"p\">:</span> <span class=\"n\">DictConfig</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">float</span><span class=\"p\">:</span>\n",
       "    <span class=\"c1\"># we want to have reproducible training</span>\n",
       "    <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># for illustrative purposes, you can reduce max_iter drastically here</span>\n",
       "    <span class=\"n\">classifier</span> <span class=\"o\">=</span> <span class=\"n\">MLPClassifier</span><span class=\"p\">(</span><span class=\"n\">hidden_layer_sizes</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">hidden_layer_sizes</span><span class=\"p\">,</span> <span class=\"n\">max_iter</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">max_iter</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">activation</span><span class=\"p\">,</span> <span class=\"n\">solver</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">solver</span><span class=\"p\">)</span>\n",
       "    <span class=\"n\">scores</span> <span class=\"o\">=</span> <span class=\"n\">cross_val_score</span><span class=\"p\">(</span><span class=\"n\">classifier</span><span class=\"p\">,</span> <span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">cv</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">return</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">scores</span><span class=\"p\">)</span> <span class=\"c1\"># mean accuracy over folds</span>\n",
       "\n",
       "<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;__main__&quot;</span><span class=\"p\">:</span>\n",
       "    <span class=\"c1\"># Ignore the warnings for now:)</span>\n",
       "    <span class=\"c1\"># We can easily create a DictConfig object with dict-like syntax</span>\n",
       "    <span class=\"c1\"># We can have almost any type in here</span>\n",
       "    <span class=\"n\">cfg</span> <span class=\"o\">=</span> <span class=\"n\">DictConfig</span><span class=\"p\">({</span>\n",
       "        <span class=\"s2\">&quot;seed&quot;</span><span class=\"p\">:</span> <span class=\"mi\">1234</span><span class=\"p\">,</span>\n",
       "        <span class=\"s2\">&quot;hidden_layer_sizes&quot;</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,),</span>\n",
       "        <span class=\"s2\">&quot;max_iter&quot;</span><span class=\"p\">:</span> <span class=\"mi\">100</span><span class=\"p\">,</span>\n",
       "        <span class=\"s2\">&quot;activation&quot;</span><span class=\"p\">:</span> <span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">,</span>\n",
       "        <span class=\"s2\">&quot;solver&quot;</span><span class=\"p\">:</span> <span class=\"s1\">&#39;adam&#39;</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">})</span>\n",
       "    <span class=\"n\">inspect</span><span class=\"p\">(</span><span class=\"n\">cfg</span><span class=\"p\">)</span>\n",
       "    \n",
       "    <span class=\"n\">cv_loss</span> <span class=\"o\">=</span> <span class=\"n\">train_mlp</span><span class=\"p\">(</span><span class=\"n\">cfg</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"p\">)</span>\n",
       "    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">&#39;Cross_validation accuaracy on digits </span><span class=\"si\">{</span><span class=\"n\">cv_loss</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn} \\PY{k+kn}{import} \\PY{n}{datasets}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{neural\\PYZus{}network} \\PY{k+kn}{import} \\PY{n}{MLPClassifier}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{cross\\PYZus{}val\\PYZus{}score}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{omegaconf} \\PY{k+kn}{import} \\PY{n}{DictConfig}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{rich} \\PY{k+kn}{import} \\PY{n+nb}{print} \\PY{k}{as} \\PY{n}{printr}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{rich} \\PY{k+kn}{import} \\PY{n}{inspect}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{exceptions} \\PY{k+kn}{import} \\PY{n}{ConvergenceWarning}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{warnings}\n",
       "\\PY{n}{warnings}\\PY{o}{.}\\PY{n}{filterwarnings}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{ignore}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{category}\\PY{o}{=}\\PY{n}{ConvergenceWarning}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} We load the digits dataset}\n",
       "\\PY{n}{digits} \\PY{o}{=} \\PY{n}{datasets}\\PY{o}{.}\\PY{n}{load\\PYZus{}digits}\\PY{p}{(}\\PY{p}{)}\n",
       "\\PY{n}{X}\\PY{p}{,} \\PY{n}{y} \\PY{o}{=} \\PY{n}{digits}\\PY{o}{.}\\PY{n}{data}\\PY{p}{,} \\PY{n}{digits}\\PY{o}{.}\\PY{n}{target}\n",
       "\n",
       "\\PY{n}{X\\PYZus{}train}\\PY{p}{,} \\PY{n}{X\\PYZus{}test}\\PY{p}{,} \\PY{n}{y\\PYZus{}train}\\PY{p}{,} \\PY{n}{y\\PYZus{}test} \\PY{o}{=} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\\PY{p}{(}\\PY{n}{X}\\PY{p}{,} \\PY{n}{y}\\PY{p}{,} \\PY{n}{test\\PYZus{}size}\\PY{o}{=}\\PY{l+m+mf}{0.33}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{train\\PYZus{}mlp}\\PY{p}{(}\\PY{n}{cfg}\\PY{p}{:} \\PY{n}{DictConfig}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n+nb}{float}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} we want to have reproducible training}\n",
       "    \\PY{n}{np}\\PY{o}{.}\\PY{n}{random}\\PY{o}{.}\\PY{n}{seed}\\PY{p}{(}\\PY{n}{seed}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{seed}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} for illustrative purposes, you can reduce max\\PYZus{}iter drastically here}\n",
       "    \\PY{n}{classifier} \\PY{o}{=} \\PY{n}{MLPClassifier}\\PY{p}{(}\\PY{n}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{p}{,} \\PY{n}{max\\PYZus{}iter}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{max\\PYZus{}iter}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{activation}\\PY{p}{,} \\PY{n}{solver}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{solver}\\PY{p}{)}\n",
       "    \\PY{n}{scores} \\PY{o}{=} \\PY{n}{cross\\PYZus{}val\\PYZus{}score}\\PY{p}{(}\\PY{n}{classifier}\\PY{p}{,} \\PY{n}{X\\PYZus{}train}\\PY{p}{,} \\PY{n}{y\\PYZus{}train}\\PY{p}{,} \\PY{n}{cv}\\PY{o}{=}\\PY{l+m+mi}{5}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{return} \\PY{n}{np}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{n}{scores}\\PY{p}{)} \\PY{c+c1}{\\PYZsh{} mean accuracy over folds}\n",
       "\n",
       "\\PY{k}{if} \\PY{n+nv+vm}{\\PYZus{}\\PYZus{}name\\PYZus{}\\PYZus{}} \\PY{o}{==} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZus{}\\PYZus{}main\\PYZus{}\\PYZus{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} Ignore the warnings for now:)}\n",
       "    \\PY{c+c1}{\\PYZsh{} We can easily create a DictConfig object with dict\\PYZhy{}like syntax}\n",
       "    \\PY{c+c1}{\\PYZsh{} We can have almost any type in here}\n",
       "    \\PY{n}{cfg} \\PY{o}{=} \\PY{n}{DictConfig}\\PY{p}{(}\\PY{p}{\\PYZob{}}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{seed}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+m+mi}{1234}\\PY{p}{,}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{p}{(}\\PY{l+m+mi}{100}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{max\\PYZus{}iter}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+m+mi}{100}\\PY{p}{,}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{activation}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{relu}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{solver}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{adam}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\n",
       "    \\PY{p}{\\PYZcb{}}\\PY{p}{)}\n",
       "    \\PY{n}{inspect}\\PY{p}{(}\\PY{n}{cfg}\\PY{p}{)}\n",
       "    \n",
       "    \\PY{n}{cv\\PYZus{}loss} \\PY{o}{=} \\PY{n}{train\\PYZus{}mlp}\\PY{p}{(}\\PY{n}{cfg}\\PY{o}{=}\\PY{n}{cfg}\\PY{p}{)}\n",
       "    \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Cross\\PYZus{}validation accuaracy on digits }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{cv\\PYZus{}loss}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn import datasets\n",
       "from sklearn.neural_network import MLPClassifier\n",
       "from sklearn.model_selection import cross_val_score\n",
       "import numpy as np\n",
       "from omegaconf import DictConfig\n",
       "from rich import print as printr\n",
       "from rich import inspect\n",
       "from sklearn.exceptions import ConvergenceWarning\n",
       "import warnings\n",
       "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
       "\n",
       "# We load the digits dataset\n",
       "digits = datasets.load_digits()\n",
       "X, y = digits.data, digits.target\n",
       "\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
       "\n",
       "\n",
       "def train_mlp(cfg: DictConfig) -> float:\n",
       "    # we want to have reproducible training\n",
       "    np.random.seed(seed=cfg.seed)\n",
       "\n",
       "    # for illustrative purposes, you can reduce max_iter drastically here\n",
       "    classifier = MLPClassifier(hidden_layer_sizes=cfg.hidden_layer_sizes, max_iter=cfg.max_iter, activation=cfg.activation, solver=cfg.solver)\n",
       "    scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
       "\n",
       "    return np.mean(scores) # mean accuracy over folds\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    # Ignore the warnings for now:)\n",
       "    # We can easily create a DictConfig object with dict-like syntax\n",
       "    # We can have almost any type in here\n",
       "    cfg = DictConfig({\n",
       "        \"seed\": 1234,\n",
       "        \"hidden_layer_sizes\": (100,),\n",
       "        \"max_iter\": 100,\n",
       "        \"activation\": 'relu',\n",
       "        \"solver\": 'adam',\n",
       "    })\n",
       "    inspect(cfg)\n",
       "    \n",
       "    cv_loss = train_mlp(cfg=cfg)\n",
       "    print(f'Cross_validation accuaracy on digits {cv_loss}')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Code(filename=\"hydra_tutorial/classic_pipeline_stillhardcoded.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m‚ï≠‚îÄ\u001b[0m\u001b[34m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[34m \u001b[0m\u001b[1;34m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'omegaconf.dictconfig.DictConfig'\u001b[0m\u001b[1;34m>\u001b[0m\u001b[34m \u001b[0m\u001b[34m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[34m‚îÄ‚ïÆ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m \u001b[32m‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\u001b[0m \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m \u001b[32m‚îÇ\u001b[0m \u001b[1m{\u001b[0m\u001b[32m'seed'\u001b[0m: \u001b[1;36m1234\u001b[0m, \u001b[32m'hidden_layer_sizes'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'max_iter'\u001b[0m: \u001b[1;36m100\u001b[0m,             \u001b[32m‚îÇ\u001b[0m \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m \u001b[32m‚îÇ\u001b[0m \u001b[32m'activation'\u001b[0m: \u001b[32m'relu'\u001b[0m, \u001b[32m'solver'\u001b[0m: \u001b[32m'adam'\u001b[0m\u001b[1m}\u001b[0m                                  \u001b[32m‚îÇ\u001b[0m \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m \u001b[32m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄÔøΩÔøΩ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m                                                                              \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m         \u001b[3;33mactivation\u001b[0m = \u001b[32m'relu'\u001b[0m                                                  \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m \u001b[3;33mhidden_layer_sizes\u001b[0m = \u001b[1m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1m]\u001b[0m                                                   \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m           \u001b[3;33mmax_iter\u001b[0m = \u001b[1;36m100\u001b[0m                                                     \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m               \u001b[3;33mseed\u001b[0m = \u001b[1;36m1234\u001b[0m                                                    \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m             \u001b[3;33msolver\u001b[0m = \u001b[32m'adam'\u001b[0m                                                  \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄÔøΩÔøΩ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
      "Cross_validation accuaracy on digits 0.9625795297372062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline_stillhardcoded.py'], returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\"python hydra_tutorial/classic_pipeline_stillhardcoded.py\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's nice but let's vary the parameters with hydra!\n",
    "Hydra can wrap your main function and pass parameters from the command line or configuration files for you -- without the hassle of writing an argument parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn</span> <span class=\"kn\">import</span> <span class=\"n\">datasets</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.neural_network</span> <span class=\"kn\">import</span> <span class=\"n\">MLPClassifier</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">cross_val_score</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">omegaconf</span> <span class=\"kn\">import</span> <span class=\"n\">DictConfig</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">hydra</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">ConvergenceWarning</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">warnings</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">hydra_tutorial.utils</span> <span class=\"kn\">import</span> <span class=\"n\">dump_logs</span>\n",
       "\n",
       "<span class=\"n\">warnings</span><span class=\"o\">.</span><span class=\"n\">filterwarnings</span><span class=\"p\">(</span><span class=\"s2\">&quot;ignore&quot;</span><span class=\"p\">,</span> <span class=\"n\">category</span><span class=\"o\">=</span><span class=\"n\">ConvergenceWarning</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># We load the digits dataset</span>\n",
       "<span class=\"n\">digits</span> <span class=\"o\">=</span> <span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">load_digits</span><span class=\"p\">()</span>\n",
       "<span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">digits</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">digits</span><span class=\"o\">.</span><span class=\"n\">target</span>\n",
       "\n",
       "<span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">X_test</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">y_test</span> <span class=\"o\">=</span> <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">test_size</span><span class=\"o\">=</span><span class=\"mf\">0.33</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "\n",
       "\n",
       "<span class=\"nd\">@hydra</span><span class=\"o\">.</span><span class=\"n\">main</span><span class=\"p\">(</span><span class=\"n\">version_base</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">config_path</span><span class=\"o\">=</span><span class=\"s2\">&quot;configs&quot;</span><span class=\"p\">,</span> <span class=\"n\">config_name</span><span class=\"o\">=</span><span class=\"s2\">&quot;base&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"k\">def</span> <span class=\"nf\">train_mlp</span><span class=\"p\">(</span><span class=\"n\">cfg</span><span class=\"p\">:</span> <span class=\"n\">DictConfig</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">float</span><span class=\"p\">:</span>\n",
       "    <span class=\"n\">warnings</span><span class=\"o\">.</span><span class=\"n\">filterwarnings</span><span class=\"p\">(</span><span class=\"s2\">&quot;ignore&quot;</span><span class=\"p\">,</span> <span class=\"n\">category</span><span class=\"o\">=</span><span class=\"n\">ConvergenceWarning</span><span class=\"p\">)</span>\n",
       "    \n",
       "    <span class=\"c1\"># we want to have reproducible training</span>\n",
       "    <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># for illustrative purposes, you can reduce max_iter drastically here</span>\n",
       "    <span class=\"n\">classifier</span> <span class=\"o\">=</span> <span class=\"n\">MLPClassifier</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">hidden_layer_sizes</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">hidden_layer_sizes</span><span class=\"p\">,</span> <span class=\"n\">max_iter</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">max_iter</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">activation</span><span class=\"p\">,</span> <span class=\"n\">solver</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">solver</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">alpha</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">alpha</span><span class=\"p\">)</span>\n",
       "    <span class=\"n\">scores</span> <span class=\"o\">=</span> <span class=\"n\">cross_val_score</span><span class=\"p\">(</span><span class=\"n\">classifier</span><span class=\"p\">,</span> <span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">cv</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"n\">mean_score</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">scores</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Mean accuracy: </span><span class=\"si\">{</span><span class=\"n\">mean_score</span><span class=\"si\">:</span><span class=\"s2\">.4f</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># Let&#39;s produce a log file</span>\n",
       "    <span class=\"n\">dump_logs</span><span class=\"p\">(</span><span class=\"n\">log_data</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s2\">&quot;mean_acc&quot;</span><span class=\"p\">:</span> <span class=\"n\">mean_score</span><span class=\"p\">},</span> <span class=\"n\">filename</span><span class=\"o\">=</span><span class=\"s2\">&quot;performance.jsonl&quot;</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">return</span> <span class=\"n\">mean_score</span> <span class=\"c1\"># mean accuracy over folds</span>\n",
       "\n",
       "<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;__main__&quot;</span><span class=\"p\">:</span>\n",
       "    <span class=\"n\">train_mlp</span><span class=\"p\">()</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn} \\PY{k+kn}{import} \\PY{n}{datasets}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{neural\\PYZus{}network} \\PY{k+kn}{import} \\PY{n}{MLPClassifier}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{cross\\PYZus{}val\\PYZus{}score}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{omegaconf} \\PY{k+kn}{import} \\PY{n}{DictConfig}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{hydra}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{exceptions} \\PY{k+kn}{import} \\PY{n}{ConvergenceWarning}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{warnings}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{hydra\\PYZus{}tutorial}\\PY{n+nn}{.}\\PY{n+nn}{utils} \\PY{k+kn}{import} \\PY{n}{dump\\PYZus{}logs}\n",
       "\n",
       "\\PY{n}{warnings}\\PY{o}{.}\\PY{n}{filterwarnings}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{ignore}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{category}\\PY{o}{=}\\PY{n}{ConvergenceWarning}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} We load the digits dataset}\n",
       "\\PY{n}{digits} \\PY{o}{=} \\PY{n}{datasets}\\PY{o}{.}\\PY{n}{load\\PYZus{}digits}\\PY{p}{(}\\PY{p}{)}\n",
       "\\PY{n}{X}\\PY{p}{,} \\PY{n}{y} \\PY{o}{=} \\PY{n}{digits}\\PY{o}{.}\\PY{n}{data}\\PY{p}{,} \\PY{n}{digits}\\PY{o}{.}\\PY{n}{target}\n",
       "\n",
       "\\PY{n}{X\\PYZus{}train}\\PY{p}{,} \\PY{n}{X\\PYZus{}test}\\PY{p}{,} \\PY{n}{y\\PYZus{}train}\\PY{p}{,} \\PY{n}{y\\PYZus{}test} \\PY{o}{=} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\\PY{p}{(}\\PY{n}{X}\\PY{p}{,} \\PY{n}{y}\\PY{p}{,} \\PY{n}{test\\PYZus{}size}\\PY{o}{=}\\PY{l+m+mf}{0.33}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{n+nd}{@hydra}\\PY{o}{.}\\PY{n}{main}\\PY{p}{(}\\PY{n}{version\\PYZus{}base}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \\PY{n}{config\\PYZus{}path}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{configs}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{config\\PYZus{}name}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{base}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{k}{def} \\PY{n+nf}{train\\PYZus{}mlp}\\PY{p}{(}\\PY{n}{cfg}\\PY{p}{:} \\PY{n}{DictConfig}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n+nb}{float}\\PY{p}{:}\n",
       "    \\PY{n}{warnings}\\PY{o}{.}\\PY{n}{filterwarnings}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{ignore}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{category}\\PY{o}{=}\\PY{n}{ConvergenceWarning}\\PY{p}{)}\n",
       "    \n",
       "    \\PY{c+c1}{\\PYZsh{} we want to have reproducible training}\n",
       "    \\PY{n}{np}\\PY{o}{.}\\PY{n}{random}\\PY{o}{.}\\PY{n}{seed}\\PY{p}{(}\\PY{n}{seed}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{seed}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} for illustrative purposes, you can reduce max\\PYZus{}iter drastically here}\n",
       "    \\PY{n}{classifier} \\PY{o}{=} \\PY{n}{MLPClassifier}\\PY{p}{(}\n",
       "        \\PY{n}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{p}{,} \\PY{n}{max\\PYZus{}iter}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{max\\PYZus{}iter}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{activation}\\PY{p}{,} \\PY{n}{solver}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{solver}\\PY{p}{,}\n",
       "        \\PY{n}{alpha}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{alpha}\\PY{p}{)}\n",
       "    \\PY{n}{scores} \\PY{o}{=} \\PY{n}{cross\\PYZus{}val\\PYZus{}score}\\PY{p}{(}\\PY{n}{classifier}\\PY{p}{,} \\PY{n}{X\\PYZus{}train}\\PY{p}{,} \\PY{n}{y\\PYZus{}train}\\PY{p}{,} \\PY{n}{cv}\\PY{o}{=}\\PY{l+m+mi}{5}\\PY{p}{)}\n",
       "\n",
       "    \\PY{n}{mean\\PYZus{}score} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{n}{scores}\\PY{p}{)}\n",
       "\n",
       "    \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Mean accuracy: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{mean\\PYZus{}score}\\PY{l+s+si}{:}\\PY{l+s+s2}{.4f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} Let\\PYZsq{}s produce a log file}\n",
       "    \\PY{n}{dump\\PYZus{}logs}\\PY{p}{(}\\PY{n}{log\\PYZus{}data}\\PY{o}{=}\\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{mean\\PYZus{}acc}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{n}{mean\\PYZus{}score}\\PY{p}{\\PYZcb{}}\\PY{p}{,} \\PY{n}{filename}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{performance.jsonl}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{return} \\PY{n}{mean\\PYZus{}score} \\PY{c+c1}{\\PYZsh{} mean accuracy over folds}\n",
       "\n",
       "\\PY{k}{if} \\PY{n+nv+vm}{\\PYZus{}\\PYZus{}name\\PYZus{}\\PYZus{}} \\PY{o}{==} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZus{}\\PYZus{}main\\PYZus{}\\PYZus{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:}\n",
       "    \\PY{n}{train\\PYZus{}mlp}\\PY{p}{(}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn import datasets\n",
       "from sklearn.neural_network import MLPClassifier\n",
       "from sklearn.model_selection import cross_val_score\n",
       "import numpy as np\n",
       "from omegaconf import DictConfig\n",
       "import hydra\n",
       "from sklearn.exceptions import ConvergenceWarning\n",
       "import warnings\n",
       "from hydra_tutorial.utils import dump_logs\n",
       "\n",
       "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
       "\n",
       "# We load the digits dataset\n",
       "digits = datasets.load_digits()\n",
       "X, y = digits.data, digits.target\n",
       "\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
       "\n",
       "\n",
       "@hydra.main(version_base=None, config_path=\"configs\", config_name=\"base\")\n",
       "def train_mlp(cfg: DictConfig) -> float:\n",
       "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
       "    \n",
       "    # we want to have reproducible training\n",
       "    np.random.seed(seed=cfg.seed)\n",
       "\n",
       "    # for illustrative purposes, you can reduce max_iter drastically here\n",
       "    classifier = MLPClassifier(\n",
       "        hidden_layer_sizes=cfg.hidden_layer_sizes, max_iter=cfg.max_iter, activation=cfg.activation, solver=cfg.solver,\n",
       "        alpha=cfg.alpha)\n",
       "    scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
       "\n",
       "    mean_score = np.mean(scores)\n",
       "\n",
       "    print(f\"Mean accuracy: {mean_score:.4f}\")\n",
       "\n",
       "    # Let's produce a log file\n",
       "    dump_logs(log_data={\"mean_acc\": mean_score}, filename=\"performance.jsonl\")\n",
       "\n",
       "    return mean_score # mean accuracy over folds\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    train_mlp()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Code(filename=\"hydra_tutorial/classic_pipeline.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we let it run, let's have a look at the configuration file.\n",
    "This will be our default as decorated by hydra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"c1\"># @package _global_</span>\n",
       "<span class=\"nt\">defaults</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">  </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">_self_</span>\n",
       "<span class=\"w\">  </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"nt\">override hydra/launcher</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">joblib</span>\n",
       "<span class=\"w\">  </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"nt\">override hydra/job_logging</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">colorlog</span>\n",
       "<span class=\"w\">  </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"nt\">override hydra/hydra_logging</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">colorlog</span>\n",
       "\n",
       "<span class=\"nt\">seed</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">1234</span>\n",
       "<span class=\"nt\">hidden_layer_sizes</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p p-Indicator\">[</span><span class=\"nv\">100</span><span class=\"p p-Indicator\">,]</span>\n",
       "<span class=\"nt\">max_iter</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">100</span>\n",
       "<span class=\"nt\">activation</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s\">&#39;relu&#39;</span>\n",
       "<span class=\"nt\">solver</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s\">&#39;adam&#39;</span>\n",
       "<span class=\"nt\">alpha</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">0.0001</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{c+c1}{\\PYZsh{} @package \\PYZus{}global\\PYZus{}}\n",
       "\\PY{n+nt}{defaults}\\PY{p}{:}\n",
       "\\PY{+w}{  }\\PY{p+pIndicator}{\\PYZhy{}}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{\\PYZus{}self\\PYZus{}}\n",
       "\\PY{+w}{  }\\PY{p+pIndicator}{\\PYZhy{}}\\PY{+w}{ }\\PY{n+nt}{override hydra/launcher}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{joblib}\n",
       "\\PY{+w}{  }\\PY{p+pIndicator}{\\PYZhy{}}\\PY{+w}{ }\\PY{n+nt}{override hydra/job\\PYZus{}logging}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{colorlog}\n",
       "\\PY{+w}{  }\\PY{p+pIndicator}{\\PYZhy{}}\\PY{+w}{ }\\PY{n+nt}{override hydra/hydra\\PYZus{}logging}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{colorlog}\n",
       "\n",
       "\\PY{n+nt}{seed}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{1234}\n",
       "\\PY{n+nt}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{p}{:}\\PY{+w}{ }\\PY{p+pIndicator}{[}\\PY{n+nv}{100}\\PY{p+pIndicator}{,}\\PY{p+pIndicator}{]}\n",
       "\\PY{n+nt}{max\\PYZus{}iter}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{100}\n",
       "\\PY{n+nt}{activation}\\PY{p}{:}\\PY{+w}{ }\\PY{l+s}{\\PYZsq{}}\\PY{l+s}{relu}\\PY{l+s}{\\PYZsq{}}\n",
       "\\PY{n+nt}{solver}\\PY{p}{:}\\PY{+w}{ }\\PY{l+s}{\\PYZsq{}}\\PY{l+s}{adam}\\PY{l+s}{\\PYZsq{}}\n",
       "\\PY{n+nt}{alpha}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{0.0001}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "# @package _global_\n",
       "defaults:\n",
       "  - _self_\n",
       "  - override hydra/launcher: joblib\n",
       "  - override hydra/job_logging: colorlog\n",
       "  - override hydra/hydra_logging: colorlog\n",
       "\n",
       "seed: 1234\n",
       "hidden_layer_sizes: [100,]\n",
       "max_iter: 100\n",
       "activation: 'relu'\n",
       "solver: 'adam'\n",
       "alpha: 0.0001"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Code(filename=\"hydra_tutorial/configs/base.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.9626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline.py'], returncode=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\"python hydra_tutorial/classic_pipeline.py\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to pass arguments via the commandline.\n",
    "This is easily possible with the [override syntax](https://hydra.cc/docs/advanced/override_grammar/basic/).\n",
    "Let's vary the hidden layer sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.8945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline.py', 'hidden_layer_sizes=[10,10,10]'], returncode=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\"python hydra_tutorial/classic_pipeline.py hidden_layer_sizes=[10,10,10]\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what really comes in handy is the ability to grid of parameter settings.\n",
    "First, to factor out randomness we want to run different seeds.\n",
    "Then, we would like to check different settings, e.g. different hidden layer sizes and different activation functions.\n",
    "\n",
    "For this we will add a list of parameter values and the flag `-m` or `--multirun` to indicate that this is a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2023-11-21 18:16:26,808\u001b[0m][\u001b[35mHYDRA\u001b[0m] Joblib.Parallel(n_jobs=-1,backend=loky,prefer=processes,require=None,verbose=0,timeout=None,pre_dispatch=2*n_jobs,batch_size=auto,temp_folder=None,max_nbytes=None,mmap_mode=r) is launching 10 jobs\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:26,809\u001b[0m][\u001b[35mHYDRA\u001b[0m] Launching jobs, sweep output dir : multirun/2023-11-21/18-16-26\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:26,809\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#0 : hidden_layer_sizes=[100] seed=1\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:26,809\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#1 : hidden_layer_sizes=[100] seed=2\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:26,809\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#2 : hidden_layer_sizes=[100] seed=3\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:26,809\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#3 : hidden_layer_sizes=[100] seed=4\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:26,809\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#4 : hidden_layer_sizes=[100] seed=5\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:26,809\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#5 : hidden_layer_sizes=[10,10,10] seed=1\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:26,809\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#6 : hidden_layer_sizes=[10,10,10] seed=2\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:26,809\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#7 : hidden_layer_sizes=[10,10,10] seed=3\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:26,809\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#8 : hidden_layer_sizes=[10,10,10] seed=4\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:26,809\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#9 : hidden_layer_sizes=[10,10,10] seed=5\u001b[0m\n",
      "Mean accuracy: 0.8412\n",
      "Mean accuracy: 0.8661\n",
      "Mean accuracy: 0.8719\n",
      "Mean accuracy: 0.8686\n",
      "Mean accuracy: 0.8678\n",
      "Mean accuracy: 0.9601\n",
      "Mean accuracy: 0.9601\n",
      "Mean accuracy: 0.9568\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error executing job with overrides: ['hidden_layer_sizes=[100]', 'seed=1']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/numina/Documents/repos/hydra_tutorial/hydra_tutorial/classic_pipeline.py\", line 39, in train_mlp\n",
      "    dump_logs(log_data={\"mean_acc\": mean_score}, filename=\"performance.jsonl\")\n",
      "      ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/numina/Documents/repos/hydra_tutorial/hydra_tutorial/utils.py\", line 33, in dump_logs\n",
      "    with open(filename, mode=\"a\") as file:\n",
      "      ^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'outputs/2023-11-21/18-16-26/performance.jsonl'\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline.py', 'hidden_layer_sizes=[100],[10,10,10]', 'seed=range(1,6)', '-m'], returncode=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\"python hydra_tutorial/classic_pipeline.py hidden_layer_sizes=[100],[10,10,10] seed=range(1,6) -m\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specifiy the number of workers on your local cluster via the config files.\n",
    "This config runs your parallel jobs with joblib.\n",
    "The config might look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"c1\"># @package _global_</span>\n",
       "<span class=\"nt\">defaults</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">  </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"nt\">override /hydra/launcher</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">joblib</span>\n",
       "\n",
       "<span class=\"nt\">hydra</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">  </span><span class=\"nt\">launcher</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">    </span><span class=\"nt\">n_jobs</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">4</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{c+c1}{\\PYZsh{} @package \\PYZus{}global\\PYZus{}}\n",
       "\\PY{n+nt}{defaults}\\PY{p}{:}\n",
       "\\PY{+w}{  }\\PY{p+pIndicator}{\\PYZhy{}}\\PY{+w}{ }\\PY{n+nt}{override /hydra/launcher}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{joblib}\n",
       "\n",
       "\\PY{n+nt}{hydra}\\PY{p}{:}\n",
       "\\PY{+w}{  }\\PY{n+nt}{launcher}\\PY{p}{:}\n",
       "\\PY{+w}{    }\\PY{n+nt}{n\\PYZus{}jobs}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{4}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "# @package _global_\n",
       "defaults:\n",
       "  - override /hydra/launcher: joblib\n",
       "\n",
       "hydra:\n",
       "  launcher:\n",
       "    n_jobs: 4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Code(filename=\"hydra_tutorial/configs/cluster/local.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2023-11-21 18:16:35,981\u001b[0m][\u001b[35mHYDRA\u001b[0m] Joblib.Parallel(n_jobs=4,backend=loky,prefer=processes,require=None,verbose=0,timeout=None,pre_dispatch=2*n_jobs,batch_size=auto,temp_folder=None,max_nbytes=None,mmap_mode=r) is launching 10 jobs\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:35,981\u001b[0m][\u001b[35mHYDRA\u001b[0m] Launching jobs, sweep output dir : multirun/2023-11-21/18-16-35\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:35,981\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#0 : hidden_layer_sizes=[100] seed=1 +cluster=local\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:35,981\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#1 : hidden_layer_sizes=[100] seed=2 +cluster=local\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:35,981\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#2 : hidden_layer_sizes=[100] seed=3 +cluster=local\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:35,982\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#3 : hidden_layer_sizes=[100] seed=4 +cluster=local\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:35,982\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#4 : hidden_layer_sizes=[100] seed=5 +cluster=local\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:35,982\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#5 : hidden_layer_sizes=[10,10,10] seed=1 +cluster=local\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:35,982\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#6 : hidden_layer_sizes=[10,10,10] seed=2 +cluster=local\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:35,982\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#7 : hidden_layer_sizes=[10,10,10] seed=3 +cluster=local\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:35,982\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#8 : hidden_layer_sizes=[10,10,10] seed=4 +cluster=local\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:35,982\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#9 : hidden_layer_sizes=[10,10,10] seed=5 +cluster=local\u001b[0m\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9601Mean accuracy: 0.9568\n",
      "\n",
      "Mean accuracy: 0.9601\n",
      "Mean accuracy: 0.8661\n",
      "Mean accuracy: 0.8686\n",
      "Mean accuracy: 0.8719\n",
      "Mean accuracy: 0.9509\n",
      "Mean accuracy: 0.8412\n",
      "Mean accuracy: 0.8678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error executing job with overrides: ['hidden_layer_sizes=[100]', 'seed=1', '+cluster=local']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/numina/Documents/repos/hydra_tutorial/hydra_tutorial/classic_pipeline.py\", line 39, in train_mlp\n",
      "    dump_logs(log_data={\"mean_acc\": mean_score}, filename=\"performance.jsonl\")\n",
      "      ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/numina/Documents/repos/hydra_tutorial/hydra_tutorial/utils.py\", line 33, in dump_logs\n",
      "    with open(filename, mode=\"a\") as file:\n",
      "      ^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'outputs/2023-11-21/18-16-35/performance.jsonl'\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline.py', 'hidden_layer_sizes=[100],[10,10,10]', 'seed=range(1,6)', '+cluster=local', '-m'], returncode=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\"python hydra_tutorial/classic_pipeline.py hidden_layer_sizes=[100],[10,10,10] seed=range(1,6) +cluster=local -m\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also dispatch parallel jobs on your slurm cluster with the following command:\n",
    "\n",
    "`python hydra_tutorial/classic_pipeline.py hidden_layer_sizes=[100],[10,10,10] seed=range(1,6) +cluster=slurm -m`\n",
    "\n",
    "and the corresponding config file looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"c1\"># @package _global_</span>\n",
       "<span class=\"nt\">defaults</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">  </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"nt\">override /hydra/launcher</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">submitit_slurm</span>\n",
       "\n",
       "<span class=\"c1\"># Check more possible options here:</span>\n",
       "<span class=\"c1\"># https://hydra.cc/docs/plugins/submitit_launcher/</span>\n",
       "<span class=\"nt\">hydra</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">  </span><span class=\"nt\">launcher</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">    </span><span class=\"c1\"># partition: normal  # Set your partition here</span>\n",
       "<span class=\"w\">    </span><span class=\"nt\">timeout_min</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">10</span>\n",
       "<span class=\"w\">    </span><span class=\"nt\">cpus_per_task</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">1</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{c+c1}{\\PYZsh{} @package \\PYZus{}global\\PYZus{}}\n",
       "\\PY{n+nt}{defaults}\\PY{p}{:}\n",
       "\\PY{+w}{  }\\PY{p+pIndicator}{\\PYZhy{}}\\PY{+w}{ }\\PY{n+nt}{override /hydra/launcher}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{submitit\\PYZus{}slurm}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Check more possible options here:}\n",
       "\\PY{c+c1}{\\PYZsh{} https://hydra.cc/docs/plugins/submitit\\PYZus{}launcher/}\n",
       "\\PY{n+nt}{hydra}\\PY{p}{:}\n",
       "\\PY{+w}{  }\\PY{n+nt}{launcher}\\PY{p}{:}\n",
       "\\PY{+w}{    }\\PY{c+c1}{\\PYZsh{} partition: normal  \\PYZsh{} Set your partition here}\n",
       "\\PY{+w}{    }\\PY{n+nt}{timeout\\PYZus{}min}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{10}\n",
       "\\PY{+w}{    }\\PY{n+nt}{cpus\\PYZus{}per\\PYZus{}task}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{1}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "# @package _global_\n",
       "defaults:\n",
       "  - override /hydra/launcher: submitit_slurm\n",
       "\n",
       "# Check more possible options here:\n",
       "# https://hydra.cc/docs/plugins/submitit_launcher/\n",
       "hydra:\n",
       "  launcher:\n",
       "    # partition: normal  # Set your partition here\n",
       "    timeout_min: 10\n",
       "    cpus_per_task: 1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Code(filename=\"hydra_tutorial/configs/cluster/slurm.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run! Here, we overwrite the launcher with the local version to test it, because we don't have a cluster at hand right now.\n",
    "For this we append `hydra/launcher=submitit_local`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2023-11-21 18:16:49,420\u001b[0m][\u001b[35mHYDRA\u001b[0m] Submitit 'local' sweep output dir : multirun/2023-11-21/18-16-48\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:49,421\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#0 : hidden_layer_sizes=[100] seed=1 +cluster=slurm\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:49,426\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#1 : hidden_layer_sizes=[100] seed=2 +cluster=slurm\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:49,430\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#2 : hidden_layer_sizes=[100] seed=3 +cluster=slurm\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:49,435\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#3 : hidden_layer_sizes=[100] seed=4 +cluster=slurm\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:49,441\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#4 : hidden_layer_sizes=[100] seed=5 +cluster=slurm\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:49,445\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#5 : hidden_layer_sizes=[10,10,10] seed=1 +cluster=slurm\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:49,450\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#6 : hidden_layer_sizes=[10,10,10] seed=2 +cluster=slurm\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:49,455\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#7 : hidden_layer_sizes=[10,10,10] seed=3 +cluster=slurm\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:49,460\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#8 : hidden_layer_sizes=[10,10,10] seed=4 +cluster=slurm\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:16:49,465\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#9 : hidden_layer_sizes=[10,10,10] seed=5 +cluster=slurm\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error executing job with overrides: ['hidden_layer_sizes=[100]', 'seed=1', '+cluster=slurm']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/numina/Documents/repos/hydra_tutorial/hydra_tutorial/classic_pipeline.py\", line 39, in train_mlp\n",
      "    dump_logs(log_data={\"mean_acc\": mean_score}, filename=\"performance.jsonl\")\n",
      "      ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/numina/Documents/repos/hydra_tutorial/hydra_tutorial/utils.py\", line 33, in dump_logs\n",
      "    with open(filename, mode=\"a\") as file:\n",
      "      ^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'outputs/2023-11-21/18-16-48/performance.jsonl'\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline.py', 'hidden_layer_sizes=[100],[10,10,10]', 'seed=range(1,6)', '+cluster=slurm', 'hydra/launcher=submitit_local', '-m'], returncode=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\"python hydra_tutorial/classic_pipeline.py hidden_layer_sizes=[100],[10,10,10] seed=range(1,6) +cluster=slurm hydra/launcher=submitit_local -m\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composition\n",
    "A great feature of hydra is that you can compose your configuration with different config files. We already did this with the cluster config, but here we do it more explicitly.\n",
    "This comes especially in handy if we want to configure different modules and experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.9343\n",
      "[\u001b[36m2023-11-21 18:17:28,819\u001b[0m][\u001b[35mHYDRA\u001b[0m] Joblib.Parallel(n_jobs=-1,backend=loky,prefer=processes,require=None,verbose=0,timeout=None,pre_dispatch=2*n_jobs,batch_size=auto,temp_folder=None,max_nbytes=None,mmap_mode=r) is launching 3 jobs\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:17:28,819\u001b[0m][\u001b[35mHYDRA\u001b[0m] Launching jobs, sweep output dir : multirun/2023-11-21/18-17-28\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:17:28,819\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#0 : +architecture=big_mlp +solver=adam\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:17:28,819\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#1 : +architecture=medium_mlp +solver=adam\u001b[0m\n",
      "[\u001b[36m2023-11-21 18:17:28,819\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#2 : +architecture=tiny_mlp +solver=adam\u001b[0m\n",
      "Mean accuracy: 0.9343\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error executing job with overrides: ['+architecture=big_mlp', '+solver=adam']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/numina/Documents/repos/hydra_tutorial/hydra_tutorial/classic_pipeline.py\", line 39, in train_mlp\n",
      "    dump_logs(log_data={\"mean_acc\": mean_score}, filename=\"performance.jsonl\")\n",
      "      ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/numina/Documents/repos/hydra_tutorial/hydra_tutorial/utils.py\", line 33, in dump_logs\n",
      "    with open(filename, mode=\"a\") as file:\n",
      "      ^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'outputs/2023-11-21/18-17-28/performance.jsonl'\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline.py', \"+architecture=glob('*')\", '+solver=adam', '-m'], returncode=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One composition\n",
    "subprocess.run(\"python hydra_tutorial/classic_pipeline.py +architecture=tiny_mlp +solver=adam\".split(\" \"))\n",
    "\n",
    "# Sweep over all in one folder\n",
    "subprocess.run(\"python hydra_tutorial/classic_pipeline.py +architecture=glob('*') +solver=adam -m\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "Hydra can also instantiate classes from config files, either fully or partially. \n",
    "This means you have full flexibility of configuring your project!\n",
    "\n",
    "Check the docs here: https://hydra.cc/docs/advanced/instantiate_objects/overview/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n",
    "We can not only run configurations in parallel, we can also do proper HPO with hydra with suitable plugins.\n",
    "Available sweepers are:\n",
    "- [Ax](https://hydra.cc/docs/plugins/ax_sweeper/)\n",
    "- [Optuna](https://hydra.cc/docs/plugins/nevergrad_sweeper/)\n",
    "- [Nevergrad](https://hydra.cc/docs/plugins/optuna_sweeper/)\n",
    "\n",
    "In addition, we are happy to announce the first alpha version of the [Hydra-SMAC-Sweeper](https://github.com/automl/hydra-smac-sweeper)! ü•≥\n",
    "We have created an interface between hydra and [SMAC3](https://github.com/automl/SMAC3).\n",
    "Make sure you installed everything via `bash install.sh`. üôÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config \u001b[1m{\u001b[0m\u001b[32m'hydra'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'run'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'dir'\u001b[0m: \u001b[32m'outputs/$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mnow:%Y-%m-%d\u001b[0m\u001b[32m}\u001b[0m\u001b[32m/$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mnow:%H-%M-%S\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m, \n",
      "\u001b[32m'sweep'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'dir'\u001b[0m: \u001b[32m'multirun/$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mnow:%Y-%m-%d\u001b[0m\u001b[32m}\u001b[0m\u001b[32m/$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mnow:%H-%M-%S\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'subdir'\u001b[0m: \n",
      "\u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mhydra.job.num\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'launcher'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'_target_'\u001b[0m: \n",
      "\u001b[32m'hydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher'\u001b[0m, \u001b[32m'n_jobs'\u001b[0m: \n",
      "\u001b[1;36m-1\u001b[0m, \u001b[32m'backend'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'prefer'\u001b[0m: \u001b[32m'processes'\u001b[0m, \u001b[32m'require'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'verbose'\u001b[0m: \u001b[1;36m0\u001b[0m, \n",
      "\u001b[32m'timeout'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'pre_dispatch'\u001b[0m: \u001b[32m'2*n_jobs'\u001b[0m, \u001b[32m'batch_size'\u001b[0m: \u001b[32m'auto'\u001b[0m, \n",
      "\u001b[32m'temp_folder'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'max_nbytes'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'mmap_mode'\u001b[0m: \u001b[32m'r'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'sweeper'\u001b[0m: \n",
      "\u001b[1m{\u001b[0m\u001b[32m'_target_'\u001b[0m: \u001b[32m'hydra_plugins.hydra_smac_sweeper.smac_sweeper.SMACSweeper'\u001b[0m, \n",
      "\u001b[32m'search_space'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'hyperparameters'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'alpha'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'uniform_float'\u001b[0m, \u001b[32m'lower'\u001b[0m:\n",
      "\u001b[1;36m1e-06\u001b[0m, \u001b[32m'upper'\u001b[0m: \u001b[1;36m0.01\u001b[0m, \u001b[32m'log'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'default_value'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32malpha\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'activation'\u001b[0m: \n",
      "\u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'categorical'\u001b[0m, \u001b[32m'choices'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'logistic'\u001b[0m, \u001b[32m'tanh'\u001b[0m, \u001b[32m'relu'\u001b[0m\u001b[1m]\u001b[0m, \n",
      "\u001b[32m'default_value'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mactivation\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'scenario'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'seed'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mseed\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'n_trials'\u001b[0m:\n",
      "\u001b[1;36m100\u001b[0m, \u001b[32m'deterministic'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'n_workers'\u001b[0m: \u001b[1;36m4\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'smac_class'\u001b[0m: \n",
      "\u001b[32m'smac.facade.blackbox_facade.BlackBoxFacade'\u001b[0m, \u001b[32m'smac_kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'dask_client'\u001b[0m: \n",
      "\u001b[3;35mNone\u001b[0m, \u001b[32m'logging_level'\u001b[0m: \u001b[1;36m20\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'help'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'app_name'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mhydra.job.name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'header'\u001b[0m:\n",
      "\u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mhydra.help.app_name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m is powered by Hydra.\\n'\u001b[0m, \u001b[32m'footer'\u001b[0m: \u001b[32m'Powered by Hydra \u001b[0m\n",
      "\u001b[32m(\u001b[0m\u001b[32mhttps://hydra.cc\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nUse --hydra-help to view Hydra specific help\\n'\u001b[0m, \u001b[32m'template'\u001b[0m:\n",
      "\u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mhydra.help.header\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\u001b[0m\u001b[32mn\u001b[0m\u001b[32m== Configuration groups ==\\nCompose your configuration \u001b[0m\n",
      "\u001b[32mfrom those groups \u001b[0m\u001b[32m(\u001b[0m\u001b[32mgroup\u001b[0m\u001b[32m=\u001b[0m\u001b[32moption\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n$APP_CONFIG_GROUPS\\n\\\u001b[0m\u001b[32mn\u001b[0m\u001b[32m== Config ==\\nOverride\u001b[0m\n",
      "\u001b[32manything in the config \u001b[0m\u001b[32m(\u001b[0m\u001b[32mfoo.\u001b[0m\u001b[32mbar\u001b[0m\u001b[32m=\u001b[0m\u001b[32mvalue\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n$CONFIG\\n\\n$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mhydra.help.footer\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n'\u001b[0m\u001b[1m}\u001b[0m, \n",
      "\u001b[32m'hydra_help'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'template'\u001b[0m: \u001b[32m\"Hydra \u001b[0m\u001b[32m(\u001b[0m\u001b[32m$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mhydra.runtime.version\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nSee \u001b[0m\n",
      "\u001b[32mhttps://hydra.cc for more info.\\n\\\u001b[0m\u001b[32mn\u001b[0m\u001b[32m== Flags ==\\n$FLAGS_HELP\\n\\\u001b[0m\u001b[32mn\u001b[0m\u001b[32m== Configuration \u001b[0m\n",
      "\u001b[32mgroups ==\\nCompose your configuration from those groups \u001b[0m\u001b[32m(\u001b[0m\u001b[32mFor example, append \u001b[0m\n",
      "\u001b[32mhydra/\u001b[0m\u001b[32mjob_logging\u001b[0m\u001b[32m=\u001b[0m\u001b[32mdisabled\u001b[0m\u001b[32m to command line\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n$HYDRA_CONFIG_GROUPS\\n\\nUse \u001b[0m\n",
      "\u001b[32m'--cfg hydra' to Show the Hydra config.\\n\"\u001b[0m, \u001b[32m'hydra_help'\u001b[0m: \u001b[32m'???'\u001b[0m\u001b[1m}\u001b[0m, \n",
      "\u001b[32m'hydra_logging'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'version'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'formatters'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'colorlog'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \n",
      "\u001b[32m'colorlog.ColoredFormatter'\u001b[0m, \u001b[32m'format'\u001b[0m: \n",
      "\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcyan\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms%\u001b[0m\u001b[32m(\u001b[0m\u001b[32masctime\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mreset\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms\u001b[0m\u001b[32m]\u001b[0m\u001b[32m[\u001b[0m\u001b[32m%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mpurple\u001b[0m\u001b[32m)\u001b[0m\u001b[32msHYDRA%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mreset\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms\u001b[0m\u001b[32m]\u001b[0m\u001b[32m %\u001b[0m\u001b[32m(\u001b[0m\u001b[32mmessage\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \n",
      "\u001b[32m'handlers'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'console'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'class'\u001b[0m: \u001b[32m'logging.StreamHandler'\u001b[0m, \u001b[32m'formatter'\u001b[0m: \n",
      "\u001b[32m'colorlog'\u001b[0m, \u001b[32m'stream'\u001b[0m: \u001b[32m'ext://sys.stdout'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'root'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'level'\u001b[0m: \u001b[32m'INFO'\u001b[0m, \n",
      "\u001b[32m'handlers'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'console'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'disable_existing_loggers'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'job_logging'\u001b[0m: \n",
      "\u001b[1m{\u001b[0m\u001b[32m'version'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'formatters'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'simple'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'format'\u001b[0m: \n",
      "\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m%\u001b[0m\u001b[32m(\u001b[0m\u001b[32masctime\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms\u001b[0m\u001b[32m]\u001b[0m\u001b[32m[\u001b[0m\u001b[32m%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mname\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms\u001b[0m\u001b[32m]\u001b[0m\u001b[32m[\u001b[0m\u001b[32m%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mlevelname\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms\u001b[0m\u001b[32m]\u001b[0m\u001b[32m - %\u001b[0m\u001b[32m(\u001b[0m\u001b[32mmessage\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'colorlog'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \n",
      "\u001b[32m'colorlog.ColoredFormatter'\u001b[0m, \u001b[32m'format'\u001b[0m: \n",
      "\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcyan\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms%\u001b[0m\u001b[32m(\u001b[0m\u001b[32masctime\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mreset\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms\u001b[0m\u001b[32m]\u001b[0m\u001b[32m[\u001b[0m\u001b[32m%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mblue\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mname\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mreset\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms\u001b[0m\u001b[32m]\u001b[0m\u001b[32m[\u001b[0m\u001b[32m%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mlog_color\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mleveln\u001b[0m\n",
      "\u001b[32mame\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms%\u001b[0m\u001b[32m(\u001b[0m\u001b[32mreset\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms\u001b[0m\u001b[32m]\u001b[0m\u001b[32m - %\u001b[0m\u001b[32m(\u001b[0m\u001b[32mmessage\u001b[0m\u001b[32m)\u001b[0m\u001b[32ms'\u001b[0m, \u001b[32m'log_colors'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'DEBUG'\u001b[0m: \u001b[32m'purple'\u001b[0m, \u001b[32m'INFO'\u001b[0m: \n",
      "\u001b[32m'green'\u001b[0m, \u001b[32m'WARNING'\u001b[0m: \u001b[32m'yellow'\u001b[0m, \u001b[32m'ERROR'\u001b[0m: \u001b[32m'red'\u001b[0m, \u001b[32m'CRITICAL'\u001b[0m: \u001b[32m'red'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'handlers'\u001b[0m: \n",
      "\u001b[1m{\u001b[0m\u001b[32m'console'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'class'\u001b[0m: \u001b[32m'logging.StreamHandler'\u001b[0m, \u001b[32m'formatter'\u001b[0m: \u001b[32m'colorlog'\u001b[0m, \n",
      "\u001b[32m'stream'\u001b[0m: \u001b[32m'ext://sys.stdout'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'file'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'class'\u001b[0m: \u001b[32m'logging.FileHandler'\u001b[0m, \n",
      "\u001b[32m'formatter'\u001b[0m: \u001b[32m'simple'\u001b[0m, \u001b[32m'filename'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mhydra.job.name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m.log'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'root'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'level'\u001b[0m: \n",
      "\u001b[32m'INFO'\u001b[0m, \u001b[32m'handlers'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'console'\u001b[0m, \u001b[32m'file'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'disable_existing_loggers'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m, \n",
      "\u001b[32m'env'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'mode'\u001b[0m: \u001b[1m<\u001b[0m\u001b[1;95mRunMode.MULTIRUN:\u001b[0m\u001b[39m \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m>\u001b[0m, \u001b[32m'searchpath'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'callbacks'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \n",
      "\u001b[32m'output_subdir'\u001b[0m: \u001b[32m'.hydra'\u001b[0m, \u001b[32m'overrides'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'hydra'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'hydra.\u001b[0m\u001b[32mmode\u001b[0m\u001b[32m=\u001b[0m\u001b[32mMULTIRUN\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m, \n",
      "\u001b[32m'task'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'+\u001b[0m\u001b[32mhpo\u001b[0m\u001b[32m=\u001b[0m\u001b[32msmac\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'job'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'classic_pipeline'\u001b[0m, \u001b[32m'chdir'\u001b[0m: \u001b[3;35mNone\u001b[0m, \n",
      "\u001b[32m'override_dirname'\u001b[0m: \u001b[32m'+\u001b[0m\u001b[32mhpo\u001b[0m\u001b[32m=\u001b[0m\u001b[32msmac\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'id'\u001b[0m: \u001b[32m'???'\u001b[0m, \u001b[32m'num'\u001b[0m: \u001b[32m'???'\u001b[0m, \u001b[32m'config_name'\u001b[0m: \n",
      "\u001b[32m'base'\u001b[0m, \u001b[32m'env_set'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'env_copy'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'config'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'override_dirname'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'kv_sep'\u001b[0m:\n",
      "\u001b[32m'='\u001b[0m, \u001b[32m'item_sep'\u001b[0m: \u001b[32m','\u001b[0m, \u001b[32m'exclude_keys'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'runtime'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'version'\u001b[0m: \u001b[32m'1.3.2'\u001b[0m, \n",
      "\u001b[32m'version_base'\u001b[0m: \u001b[32m'1.3'\u001b[0m, \u001b[32m'cwd'\u001b[0m: \u001b[32m'/home/numina/Documents/repos/hydra_tutorial'\u001b[0m, \n",
      "\u001b[32m'config_sources'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'path'\u001b[0m: \u001b[32m'hydra.conf'\u001b[0m, \u001b[32m'schema'\u001b[0m: \u001b[32m'pkg'\u001b[0m, \u001b[32m'provider'\u001b[0m: \u001b[32m'hydra'\u001b[0m\u001b[1m}\u001b[0m,\n",
      "\u001b[1m{\u001b[0m\u001b[32m'path'\u001b[0m: \u001b[32m'/home/numina/Documents/repos/hydra_tutorial/hydra_tutorial/configs'\u001b[0m, \n",
      "\u001b[32m'schema'\u001b[0m: \u001b[32m'file'\u001b[0m, \u001b[32m'provider'\u001b[0m: \u001b[32m'main'\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'path'\u001b[0m: \n",
      "\u001b[32m'hydra_plugins.hydra_colorlog.conf'\u001b[0m, \u001b[32m'schema'\u001b[0m: \u001b[32m'pkg'\u001b[0m, \u001b[32m'provider'\u001b[0m: \n",
      "\u001b[32m'hydra-colorlog'\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'path'\u001b[0m: \u001b[32m''\u001b[0m, \u001b[32m'schema'\u001b[0m: \u001b[32m'structured'\u001b[0m, \u001b[32m'provider'\u001b[0m: \u001b[32m'schema'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m, \n",
      "\u001b[32m'output_dir'\u001b[0m: \u001b[32m'???'\u001b[0m, \u001b[32m'choices'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'hpo'\u001b[0m: \u001b[32m'smac'\u001b[0m, \u001b[32m'hydra/env'\u001b[0m: \u001b[32m'default'\u001b[0m, \n",
      "\u001b[32m'hydra/callbacks'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'hydra/job_logging'\u001b[0m: \u001b[32m'colorlog'\u001b[0m, \u001b[32m'hydra/hydra_logging'\u001b[0m:\n",
      "\u001b[32m'colorlog'\u001b[0m, \u001b[32m'hydra/hydra_help'\u001b[0m: \u001b[32m'default'\u001b[0m, \u001b[32m'hydra/help'\u001b[0m: \u001b[32m'default'\u001b[0m, \n",
      "\u001b[32m'hydra/sweeper'\u001b[0m: \u001b[32m'SMAC'\u001b[0m, \u001b[32m'hydra/launcher'\u001b[0m: \u001b[32m'joblib'\u001b[0m, \u001b[32m'hydra/output'\u001b[0m: \n",
      "\u001b[32m'default'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'verbose'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'seed'\u001b[0m: \u001b[1;36m1234\u001b[0m, \u001b[32m'hidden_layer_sizes'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1m]\u001b[0m, \n",
      "\u001b[32m'max_iter'\u001b[0m: \u001b[1;36m100\u001b[0m, \u001b[32m'activation'\u001b[0m: \u001b[32m'relu'\u001b[0m, \u001b[32m'solver'\u001b[0m: \u001b[32m'adam'\u001b[0m, \u001b[32m'alpha'\u001b[0m: \u001b[1;36m0.0001\u001b[0m\u001b[1m}\u001b[0m\n",
      "Hydra context\n",
      "\u001b[1;35mHydraContext\u001b[0m\u001b[1m(\u001b[0m\n",
      "    \u001b[33mconfig_loader\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mhydra._internal.config_loader_impl.ConfigLoaderImpl\u001b[0m\u001b[39m object at\u001b[0m\n",
      "\u001b[1;36m0x7fb70b64ca10\u001b[0m\u001b[39m>,\u001b[0m\n",
      "\u001b[39m    \u001b[0m\u001b[33mcallbacks\u001b[0m\u001b[39m=<hydra._internal.callbacks.Callbacks object at \u001b[0m\u001b[1;36m0x7fb70b6b0f90\u001b[0m\u001b[1m>\u001b[0m\n",
      "\u001b[1m)\u001b[0m\n",
      "Launcher \u001b[1m<\u001b[0m\u001b[1;95mhydra_plugins.hydra_joblib_launcher.joblib_launcher.JoblibLauncher\u001b[0m\u001b[39m \u001b[0m\n",
      "\u001b[39mobject at \u001b[0m\u001b[1;36m0x7fb70ad386d0\u001b[0m\u001b[1m>\u001b[0m\n",
      "\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'smac.facade.blackbox_facade.BlackBoxFacade'\u001b[0m\u001b[1m>\u001b[0m\n",
      "\u001b[1m{\u001b[0m\n",
      "    \u001b[32m'dask_client'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "    \u001b[32m'logging_level'\u001b[0m: \u001b[1;36m20\u001b[0m,\n",
      "    \u001b[32m'scenario'\u001b[0m: \u001b[1;35mScenario\u001b[0m\u001b[1m(\u001b[0m\n",
      "        \u001b[33mconfigspace\u001b[0m=\u001b[35mConfiguration\u001b[0m space object:\n",
      "  Hyperparameters:\n",
      "    activation, Type: Categorical, Choices: \u001b[1m{\u001b[0mlogistic, tanh, relu\u001b[1m}\u001b[0m, Default: \n",
      "logistic\n",
      "    alpha, Type: UniformFloat, Range: \u001b[1m[\u001b[0m\u001b[1;36m1e-06\u001b[0m, \u001b[1;36m0.01\u001b[0m\u001b[1m]\u001b[0m, Default: \u001b[1;36m0.0001\u001b[0m, on \n",
      "log-scale\n",
      ",\n",
      "        \u001b[33mname\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "        \u001b[33moutput_directory\u001b[0m=\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'multirun/2023-11-21/18-21-35/smac3_output'\u001b[0m\u001b[1m)\u001b[0m,\n",
      "        \u001b[33mdeterministic\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
      "        \u001b[33mobjectives\u001b[0m=\u001b[32m'cost'\u001b[0m,\n",
      "        \u001b[33mcrash_cost\u001b[0m=\u001b[35minf\u001b[0m,\n",
      "        \u001b[33mtermination_cost_threshold\u001b[0m=\u001b[35minf\u001b[0m,\n",
      "        \u001b[33mwalltime_limit\u001b[0m=\u001b[35minf\u001b[0m,\n",
      "        \u001b[33mcputime_limit\u001b[0m=\u001b[35minf\u001b[0m,\n",
      "        \u001b[33mtrial_walltime_limit\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "        \u001b[33mtrial_memory_limit\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "        \u001b[33mn_trials\u001b[0m=\u001b[1;36m100\u001b[0m,\n",
      "        \u001b[33muse_default_config\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
      "        \u001b[33minstances\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "        \u001b[33minstance_features\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "        \u001b[33mmin_budget\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "        \u001b[33mmax_budget\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "        \u001b[33mseed\u001b[0m=\u001b[1;36m1234\u001b[0m,\n",
      "        \u001b[33mn_workers\u001b[0m=\u001b[1;36m4\u001b[0m\n",
      "    \u001b[1m)\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "[WARNING][target_function_runner.py:72] The argument budget is not set by SMAC: Consider removing it from the target function.\n",
      "[WARNING][target_function_runner.py:72] The argument instance is not set by SMAC: Consider removing it from the target function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/numina/Documents/repos/hydra_tutorial/hydra-smac-sweeper/hydra_plugins/hydra_smac_sweeper/smac_sweeper_backend.py:291: UserWarning: Override arguments might not have an effect if they are a sweep. ['+hpo=smac']\n",
      "  warnings.warn(f\"Override arguments might not have an effect if they are a sweep. {arguments}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_initial_design.py:147] Using 16 initial design configurations and 0 additional configurations.\n",
      "[INFO][abstract_intensifier.py:305] Using only one seed for deterministic scenario.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "Mean accuracy: 0.9584\n",
      "Mean accuracy: 0.9609\n",
      "[INFO][abstract_intensifier.py:515] Added config ec7abb as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:590] Added config 311943 and rejected config ec7abb as incumbent because it is not better than the incumbents on 1 instances:\n",
      "Mean accuracy: 0.9634\n",
      "[INFO][abstract_intensifier.py:590] Added config 4486e7 and rejected config 311943 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9592\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9617\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9609\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9584\n",
      "Mean accuracy: 0.9576\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9642\n",
      "[INFO][abstract_intensifier.py:590] Added config e160ad and rejected config 4486e7 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "Mean accuracy: 0.9642\n",
      "Mean accuracy: 0.9642\n",
      "Mean accuracy: 0.9642\n",
      "Mean accuracy: 0.9642\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9642\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9642\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9592\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9576\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9592\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9576\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9617\n",
      "Mean accuracy: 0.9617\n",
      "Mean accuracy: 0.9617\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9617\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9617\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9617\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9617\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9617\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9626\n",
      "Mean accuracy: 0.9626\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: inf\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 0\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "Mean accuracy: 0.9634\n",
      "[INFO][smbo.py:592] \n",
      "--- STATISTICS -------------------------------------\n",
      "--- Incumbent changed: 4\n",
      "--- Submitted trials: 100 / 100\n",
      "--- Finished trials: 100 / 100\n",
      "--- Configurations: 100\n",
      "--- Used wallclock time: 134 / inf sec\n",
      "--- Used target function runtime: 510.73 / inf sec\n",
      "----------------------------------------------------\n",
      "[INFO][smac_sweeper_backend.py:299] Final Incumbent: Configuration(values={\n",
      "  'activation': 'tanh',\n",
      "  'alpha': 0.0027851169007267708,\n",
      "})\n",
      "[INFO][smac_sweeper_backend.py:302] Estimated cost of incumbent: 0.03575726141078839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline.py', '+hpo=smac', '-m'], returncode=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\"python hydra_tutorial/classic_pipeline.py +hpo=smac -m\".split(\" \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
