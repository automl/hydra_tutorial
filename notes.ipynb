{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure\n",
    "1. classic pipeline, params hardcoded everywhere\n",
    "2. parametrizable function, introduce DictConfig\n",
    "3. hydra decorates, introduce configuration file\n",
    "4. introduce override syntax commandline\n",
    "5. introduce sweeps (e.g. multiple seeds), sequential\n",
    "6. introduce launchers (local: joblib, but also slurm/submitit)\n",
    "7. introduce composition\n",
    "8. introduce instantiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML Fall School 2023 Hydra Hands-On\n",
    "\n",
    "Welcome to our tutorial session on [hydra](hydra.cc)! üêç\n",
    "Hydra is a tool for configuring and running your experiments and optimization is seemlessly integrated.\n",
    "\n",
    "Hydra can:\n",
    "\n",
    "* Hierarchical configuration composable from multiple sources\n",
    "* Configuration can be specified or overridden from the command line\n",
    "* Dynamic command line tab completion\n",
    "* Run your application locally or launch it to run remotely\n",
    "* Run multiple jobs with different arguments with a single command\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Classical Training Pipeline\n",
    "\n",
    "(This part of the tutorial is the same as in the SMAC tutorial).\n",
    "\n",
    "We'll start with your classical optimization task.\n",
    "The task is to optimize the hyperparameters of a [sklearn.neural_network.MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) on the [digits](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) dataset. Usually we have some training pipeline with a dataset, a configured model[^1] and some validation procedure to check for generalization performance like this:\n",
    "\n",
    "\n",
    "[^1]: If we check out the documentation, we will see that loads of design decisions (hyperparameters) are already set to a default value for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn</span> <span class=\"kn\">import</span> <span class=\"n\">datasets</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.neural_network</span> <span class=\"kn\">import</span> <span class=\"n\">MLPClassifier</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">cross_val_score</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "\n",
       "<span class=\"c1\"># We load the digits dataset</span>\n",
       "<span class=\"n\">digits</span> <span class=\"o\">=</span> <span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">load_digits</span><span class=\"p\">()</span>\n",
       "<span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">digits</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">digits</span><span class=\"o\">.</span><span class=\"n\">target</span>\n",
       "\n",
       "<span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">X_test</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">y_test</span> <span class=\"o\">=</span> <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">test_size</span><span class=\"o\">=</span><span class=\"mf\">0.33</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">train_mlp</span><span class=\"p\">()</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">float</span><span class=\"p\">:</span>\n",
       "    <span class=\"c1\"># we want to have reproducible training</span>\n",
       "    <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"mi\">1234</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># for illustrative purposes, you can reduce max_iter drastically here</span>\n",
       "    <span class=\"n\">classifier</span> <span class=\"o\">=</span> <span class=\"n\">MLPClassifier</span><span class=\"p\">(</span><span class=\"n\">hidden_layer_sizes</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,),</span> <span class=\"n\">max_iter</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">,</span> <span class=\"n\">solver</span><span class=\"o\">=</span><span class=\"s1\">&#39;adam&#39;</span><span class=\"p\">)</span>\n",
       "    <span class=\"n\">scores</span> <span class=\"o\">=</span> <span class=\"n\">cross_val_score</span><span class=\"p\">(</span><span class=\"n\">classifier</span><span class=\"p\">,</span> <span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">cv</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">return</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">scores</span><span class=\"p\">)</span> <span class=\"c1\"># mean accuracy over folds</span>\n",
       "\n",
       "<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;__main__&quot;</span><span class=\"p\">:</span>\n",
       "    <span class=\"c1\"># Ignore the warnings for now:)</span>\n",
       "    <span class=\"n\">cv_loss</span> <span class=\"o\">=</span> <span class=\"n\">train_mlp</span><span class=\"p\">()</span>\n",
       "    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">&#39;Cross_validation accuaracy on digits </span><span class=\"si\">{</span><span class=\"n\">cv_loss</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn} \\PY{k+kn}{import} \\PY{n}{datasets}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{neural\\PYZus{}network} \\PY{k+kn}{import} \\PY{n}{MLPClassifier}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{cross\\PYZus{}val\\PYZus{}score}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} We load the digits dataset}\n",
       "\\PY{n}{digits} \\PY{o}{=} \\PY{n}{datasets}\\PY{o}{.}\\PY{n}{load\\PYZus{}digits}\\PY{p}{(}\\PY{p}{)}\n",
       "\\PY{n}{X}\\PY{p}{,} \\PY{n}{y} \\PY{o}{=} \\PY{n}{digits}\\PY{o}{.}\\PY{n}{data}\\PY{p}{,} \\PY{n}{digits}\\PY{o}{.}\\PY{n}{target}\n",
       "\n",
       "\\PY{n}{X\\PYZus{}train}\\PY{p}{,} \\PY{n}{X\\PYZus{}test}\\PY{p}{,} \\PY{n}{y\\PYZus{}train}\\PY{p}{,} \\PY{n}{y\\PYZus{}test} \\PY{o}{=} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\\PY{p}{(}\\PY{n}{X}\\PY{p}{,} \\PY{n}{y}\\PY{p}{,} \\PY{n}{test\\PYZus{}size}\\PY{o}{=}\\PY{l+m+mf}{0.33}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{train\\PYZus{}mlp}\\PY{p}{(}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n+nb}{float}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} we want to have reproducible training}\n",
       "    \\PY{n}{np}\\PY{o}{.}\\PY{n}{random}\\PY{o}{.}\\PY{n}{seed}\\PY{p}{(}\\PY{n}{seed}\\PY{o}{=}\\PY{l+m+mi}{1234}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} for illustrative purposes, you can reduce max\\PYZus{}iter drastically here}\n",
       "    \\PY{n}{classifier} \\PY{o}{=} \\PY{n}{MLPClassifier}\\PY{p}{(}\\PY{n}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{o}{=}\\PY{p}{(}\\PY{l+m+mi}{100}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{max\\PYZus{}iter}\\PY{o}{=}\\PY{l+m+mi}{100}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{relu}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{solver}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{adam}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "    \\PY{n}{scores} \\PY{o}{=} \\PY{n}{cross\\PYZus{}val\\PYZus{}score}\\PY{p}{(}\\PY{n}{classifier}\\PY{p}{,} \\PY{n}{X\\PYZus{}train}\\PY{p}{,} \\PY{n}{y\\PYZus{}train}\\PY{p}{,} \\PY{n}{cv}\\PY{o}{=}\\PY{l+m+mi}{5}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{return} \\PY{n}{np}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{n}{scores}\\PY{p}{)} \\PY{c+c1}{\\PYZsh{} mean accuracy over folds}\n",
       "\n",
       "\\PY{k}{if} \\PY{n+nv+vm}{\\PYZus{}\\PYZus{}name\\PYZus{}\\PYZus{}} \\PY{o}{==} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZus{}\\PYZus{}main\\PYZus{}\\PYZus{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} Ignore the warnings for now:)}\n",
       "    \\PY{n}{cv\\PYZus{}loss} \\PY{o}{=} \\PY{n}{train\\PYZus{}mlp}\\PY{p}{(}\\PY{p}{)}\n",
       "    \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Cross\\PYZus{}validation accuaracy on digits }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{cv\\PYZus{}loss}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn import datasets\n",
       "from sklearn.neural_network import MLPClassifier\n",
       "from sklearn.model_selection import cross_val_score\n",
       "import numpy as np\n",
       "\n",
       "# We load the digits dataset\n",
       "digits = datasets.load_digits()\n",
       "X, y = digits.data, digits.target\n",
       "\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
       "\n",
       "def train_mlp() -> float:\n",
       "    # we want to have reproducible training\n",
       "    np.random.seed(seed=1234)\n",
       "\n",
       "    # for illustrative purposes, you can reduce max_iter drastically here\n",
       "    classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=100, activation='relu', solver='adam')\n",
       "    scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
       "\n",
       "    return np.mean(scores) # mean accuracy over folds\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    # Ignore the warnings for now:)\n",
       "    cv_loss = train_mlp()\n",
       "    print(f'Cross_validation accuaracy on digits {cv_loss}')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Code\n",
    "Code(filename=\"hydra_tutorial/classic_pipeline_hardcoded.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/numina/Documents/repos/hydra_tutorial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_validation accuaracy on digits 0.9625795297372062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline_hardcoded.py'], returncode=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run(\"python hydra_tutorial/classic_pipeline_hardcoded.py\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You can ignore the errors above regarding not converging for now.\n",
    "\n",
    "What we can see in this example is that we hardcoded many (hyper-)parameters. But maybe we would like to vary them? So let's adapt our `train_mlp` function!\n",
    "We will use a dict-like object to hold all our parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn</span> <span class=\"kn\">import</span> <span class=\"n\">datasets</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.neural_network</span> <span class=\"kn\">import</span> <span class=\"n\">MLPClassifier</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">cross_val_score</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">omegaconf</span> <span class=\"kn\">import</span> <span class=\"n\">DictConfig</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">rich</span> <span class=\"kn\">import</span> <span class=\"nb\">print</span> <span class=\"k\">as</span> <span class=\"n\">printr</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">rich</span> <span class=\"kn\">import</span> <span class=\"n\">inspect</span>\n",
       "\n",
       "<span class=\"c1\"># We load the digits dataset</span>\n",
       "<span class=\"n\">digits</span> <span class=\"o\">=</span> <span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">load_digits</span><span class=\"p\">()</span>\n",
       "<span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">digits</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">digits</span><span class=\"o\">.</span><span class=\"n\">target</span>\n",
       "\n",
       "<span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">X_test</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">y_test</span> <span class=\"o\">=</span> <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">test_size</span><span class=\"o\">=</span><span class=\"mf\">0.33</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">train_mlp</span><span class=\"p\">(</span><span class=\"n\">cfg</span><span class=\"p\">:</span> <span class=\"n\">DictConfig</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">float</span><span class=\"p\">:</span>\n",
       "    <span class=\"c1\"># we want to have reproducible training</span>\n",
       "    <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># for illustrative purposes, you can reduce max_iter drastically here</span>\n",
       "    <span class=\"n\">classifier</span> <span class=\"o\">=</span> <span class=\"n\">MLPClassifier</span><span class=\"p\">(</span><span class=\"n\">hidden_layer_sizes</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">hidden_layer_sizes</span><span class=\"p\">,</span> <span class=\"n\">max_iter</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">max_iter</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">activation</span><span class=\"p\">,</span> <span class=\"n\">solver</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">solver</span><span class=\"p\">)</span>\n",
       "    <span class=\"n\">scores</span> <span class=\"o\">=</span> <span class=\"n\">cross_val_score</span><span class=\"p\">(</span><span class=\"n\">classifier</span><span class=\"p\">,</span> <span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">cv</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">return</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">scores</span><span class=\"p\">)</span> <span class=\"c1\"># mean accuracy over folds</span>\n",
       "\n",
       "<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;__main__&quot;</span><span class=\"p\">:</span>\n",
       "    <span class=\"c1\"># Ignore the warnings for now:)</span>\n",
       "    <span class=\"c1\"># We can easily create a DictConfig object with dict-like syntax</span>\n",
       "    <span class=\"c1\"># We can have almost any type in here</span>\n",
       "    <span class=\"n\">cfg</span> <span class=\"o\">=</span> <span class=\"n\">DictConfig</span><span class=\"p\">({</span>\n",
       "        <span class=\"s2\">&quot;seed&quot;</span><span class=\"p\">:</span> <span class=\"mi\">1234</span><span class=\"p\">,</span>\n",
       "        <span class=\"s2\">&quot;hidden_layer_sizes&quot;</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,),</span>\n",
       "        <span class=\"s2\">&quot;max_iter&quot;</span><span class=\"p\">:</span> <span class=\"mi\">100</span><span class=\"p\">,</span>\n",
       "        <span class=\"s2\">&quot;activation&quot;</span><span class=\"p\">:</span> <span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">,</span>\n",
       "        <span class=\"s2\">&quot;solver&quot;</span><span class=\"p\">:</span> <span class=\"s1\">&#39;adam&#39;</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">})</span>\n",
       "    <span class=\"n\">inspect</span><span class=\"p\">(</span><span class=\"n\">cfg</span><span class=\"p\">)</span>\n",
       "    \n",
       "    <span class=\"n\">cv_loss</span> <span class=\"o\">=</span> <span class=\"n\">train_mlp</span><span class=\"p\">(</span><span class=\"n\">cfg</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"p\">)</span>\n",
       "    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s1\">&#39;Cross_validation accuaracy on digits </span><span class=\"si\">{</span><span class=\"n\">cv_loss</span><span class=\"si\">}</span><span class=\"s1\">&#39;</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn} \\PY{k+kn}{import} \\PY{n}{datasets}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{neural\\PYZus{}network} \\PY{k+kn}{import} \\PY{n}{MLPClassifier}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{cross\\PYZus{}val\\PYZus{}score}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{omegaconf} \\PY{k+kn}{import} \\PY{n}{DictConfig}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{rich} \\PY{k+kn}{import} \\PY{n+nb}{print} \\PY{k}{as} \\PY{n}{printr}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{rich} \\PY{k+kn}{import} \\PY{n}{inspect}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} We load the digits dataset}\n",
       "\\PY{n}{digits} \\PY{o}{=} \\PY{n}{datasets}\\PY{o}{.}\\PY{n}{load\\PYZus{}digits}\\PY{p}{(}\\PY{p}{)}\n",
       "\\PY{n}{X}\\PY{p}{,} \\PY{n}{y} \\PY{o}{=} \\PY{n}{digits}\\PY{o}{.}\\PY{n}{data}\\PY{p}{,} \\PY{n}{digits}\\PY{o}{.}\\PY{n}{target}\n",
       "\n",
       "\\PY{n}{X\\PYZus{}train}\\PY{p}{,} \\PY{n}{X\\PYZus{}test}\\PY{p}{,} \\PY{n}{y\\PYZus{}train}\\PY{p}{,} \\PY{n}{y\\PYZus{}test} \\PY{o}{=} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\\PY{p}{(}\\PY{n}{X}\\PY{p}{,} \\PY{n}{y}\\PY{p}{,} \\PY{n}{test\\PYZus{}size}\\PY{o}{=}\\PY{l+m+mf}{0.33}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{train\\PYZus{}mlp}\\PY{p}{(}\\PY{n}{cfg}\\PY{p}{:} \\PY{n}{DictConfig}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n+nb}{float}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} we want to have reproducible training}\n",
       "    \\PY{n}{np}\\PY{o}{.}\\PY{n}{random}\\PY{o}{.}\\PY{n}{seed}\\PY{p}{(}\\PY{n}{seed}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{seed}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} for illustrative purposes, you can reduce max\\PYZus{}iter drastically here}\n",
       "    \\PY{n}{classifier} \\PY{o}{=} \\PY{n}{MLPClassifier}\\PY{p}{(}\\PY{n}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{p}{,} \\PY{n}{max\\PYZus{}iter}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{max\\PYZus{}iter}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{activation}\\PY{p}{,} \\PY{n}{solver}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{solver}\\PY{p}{)}\n",
       "    \\PY{n}{scores} \\PY{o}{=} \\PY{n}{cross\\PYZus{}val\\PYZus{}score}\\PY{p}{(}\\PY{n}{classifier}\\PY{p}{,} \\PY{n}{X\\PYZus{}train}\\PY{p}{,} \\PY{n}{y\\PYZus{}train}\\PY{p}{,} \\PY{n}{cv}\\PY{o}{=}\\PY{l+m+mi}{5}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{return} \\PY{n}{np}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{n}{scores}\\PY{p}{)} \\PY{c+c1}{\\PYZsh{} mean accuracy over folds}\n",
       "\n",
       "\\PY{k}{if} \\PY{n+nv+vm}{\\PYZus{}\\PYZus{}name\\PYZus{}\\PYZus{}} \\PY{o}{==} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZus{}\\PYZus{}main\\PYZus{}\\PYZus{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} Ignore the warnings for now:)}\n",
       "    \\PY{c+c1}{\\PYZsh{} We can easily create a DictConfig object with dict\\PYZhy{}like syntax}\n",
       "    \\PY{c+c1}{\\PYZsh{} We can have almost any type in here}\n",
       "    \\PY{n}{cfg} \\PY{o}{=} \\PY{n}{DictConfig}\\PY{p}{(}\\PY{p}{\\PYZob{}}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{seed}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+m+mi}{1234}\\PY{p}{,}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{p}{(}\\PY{l+m+mi}{100}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{max\\PYZus{}iter}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+m+mi}{100}\\PY{p}{,}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{activation}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{relu}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{solver}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{adam}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\n",
       "    \\PY{p}{\\PYZcb{}}\\PY{p}{)}\n",
       "    \\PY{n}{inspect}\\PY{p}{(}\\PY{n}{cfg}\\PY{p}{)}\n",
       "    \n",
       "    \\PY{n}{cv\\PYZus{}loss} \\PY{o}{=} \\PY{n}{train\\PYZus{}mlp}\\PY{p}{(}\\PY{n}{cfg}\\PY{o}{=}\\PY{n}{cfg}\\PY{p}{)}\n",
       "    \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Cross\\PYZus{}validation accuaracy on digits }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{cv\\PYZus{}loss}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn import datasets\n",
       "from sklearn.neural_network import MLPClassifier\n",
       "from sklearn.model_selection import cross_val_score\n",
       "import numpy as np\n",
       "from omegaconf import DictConfig\n",
       "from rich import print as printr\n",
       "from rich import inspect\n",
       "\n",
       "# We load the digits dataset\n",
       "digits = datasets.load_digits()\n",
       "X, y = digits.data, digits.target\n",
       "\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
       "\n",
       "\n",
       "def train_mlp(cfg: DictConfig) -> float:\n",
       "    # we want to have reproducible training\n",
       "    np.random.seed(seed=cfg.seed)\n",
       "\n",
       "    # for illustrative purposes, you can reduce max_iter drastically here\n",
       "    classifier = MLPClassifier(hidden_layer_sizes=cfg.hidden_layer_sizes, max_iter=cfg.max_iter, activation=cfg.activation, solver=cfg.solver)\n",
       "    scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
       "\n",
       "    return np.mean(scores) # mean accuracy over folds\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    # Ignore the warnings for now:)\n",
       "    # We can easily create a DictConfig object with dict-like syntax\n",
       "    # We can have almost any type in here\n",
       "    cfg = DictConfig({\n",
       "        \"seed\": 1234,\n",
       "        \"hidden_layer_sizes\": (100,),\n",
       "        \"max_iter\": 100,\n",
       "        \"activation\": 'relu',\n",
       "        \"solver\": 'adam',\n",
       "    })\n",
       "    inspect(cfg)\n",
       "    \n",
       "    cv_loss = train_mlp(cfg=cfg)\n",
       "    print(f'Cross_validation accuaracy on digits {cv_loss}')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Code(filename=\"hydra_tutorial/classic_pipeline_stillhardcoded.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m‚ï≠‚îÄ\u001b[0m\u001b[34m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[34m \u001b[0m\u001b[1;34m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'omegaconf.dictconfig.DictConfig'\u001b[0m\u001b[1;34m>\u001b[0m\u001b[34m \u001b[0m\u001b[34m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[34m‚îÄ‚ïÆ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m \u001b[32m‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\u001b[0m \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m \u001b[32m‚îÇ\u001b[0m \u001b[1m{\u001b[0m\u001b[32m'seed'\u001b[0m: \u001b[1;36m1234\u001b[0m, \u001b[32m'hidden_layer_sizes'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'max_iter'\u001b[0m: \u001b[1;36m100\u001b[0m,             \u001b[32m‚îÇ\u001b[0m \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m \u001b[32m‚îÇ\u001b[0m \u001b[32m'activation'\u001b[0m: \u001b[32m'relu'\u001b[0m, \u001b[32m'solver'\u001b[0m: \u001b[32m'adam'\u001b[0m\u001b[1m}\u001b[0m                                  \u001b[32m‚îÇ\u001b[0m \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m \u001b[32m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄÔøΩÔøΩ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m                                                                              \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m         \u001b[3;33mactivation\u001b[0m = \u001b[32m'relu'\u001b[0m                                                  \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m \u001b[3;33mhidden_layer_sizes\u001b[0m = \u001b[1m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1m]\u001b[0m                                                   \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m           \u001b[3;33mmax_iter\u001b[0m = \u001b[1;36m100\u001b[0m                                                     \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m               \u001b[3;33mseed\u001b[0m = \u001b[1;36m1234\u001b[0m                                                    \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m             \u001b[3;33msolver\u001b[0m = \u001b[32m'adam'\u001b[0m                                                  \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄÔøΩÔøΩ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_validation accuaracy on digits 0.9625795297372062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline_stillhardcoded.py'], returncode=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\"python hydra_tutorial/classic_pipeline_stillhardcoded.py\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's nice but let's vary the parameters with hydra!\n",
    "Hydra can wrap your main function and pass parameters from the command line or configuration files for you -- without the hassle of writing an argument parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn</span> <span class=\"kn\">import</span> <span class=\"n\">datasets</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.neural_network</span> <span class=\"kn\">import</span> <span class=\"n\">MLPClassifier</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">cross_val_score</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">omegaconf</span> <span class=\"kn\">import</span> <span class=\"n\">DictConfig</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">hydra</span>\n",
       "\n",
       "<span class=\"c1\"># We load the digits dataset</span>\n",
       "<span class=\"n\">digits</span> <span class=\"o\">=</span> <span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">load_digits</span><span class=\"p\">()</span>\n",
       "<span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">digits</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">digits</span><span class=\"o\">.</span><span class=\"n\">target</span>\n",
       "\n",
       "<span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">X_test</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">y_test</span> <span class=\"o\">=</span> <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">test_size</span><span class=\"o\">=</span><span class=\"mf\">0.33</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "\n",
       "\n",
       "<span class=\"nd\">@hydra</span><span class=\"o\">.</span><span class=\"n\">main</span><span class=\"p\">(</span><span class=\"n\">version_base</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">config_path</span><span class=\"o\">=</span><span class=\"s2\">&quot;configs&quot;</span><span class=\"p\">,</span> <span class=\"n\">config_name</span><span class=\"o\">=</span><span class=\"s2\">&quot;base&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"k\">def</span> <span class=\"nf\">train_mlp</span><span class=\"p\">(</span><span class=\"n\">cfg</span><span class=\"p\">:</span> <span class=\"n\">DictConfig</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">float</span><span class=\"p\">:</span>\n",
       "    <span class=\"c1\"># we want to have reproducible training</span>\n",
       "    <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># for illustrative purposes, you can reduce max_iter drastically here</span>\n",
       "    <span class=\"n\">classifier</span> <span class=\"o\">=</span> <span class=\"n\">MLPClassifier</span><span class=\"p\">(</span><span class=\"n\">hidden_layer_sizes</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">hidden_layer_sizes</span><span class=\"p\">,</span> <span class=\"n\">max_iter</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">max_iter</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">activation</span><span class=\"p\">,</span> <span class=\"n\">solver</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">solver</span><span class=\"p\">)</span>\n",
       "    <span class=\"n\">scores</span> <span class=\"o\">=</span> <span class=\"n\">cross_val_score</span><span class=\"p\">(</span><span class=\"n\">classifier</span><span class=\"p\">,</span> <span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">cv</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"n\">mean_score</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">scores</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Mean accuracy: </span><span class=\"si\">{</span><span class=\"n\">mean_score</span><span class=\"si\">:</span><span class=\"s2\">.4f</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">return</span> <span class=\"n\">mean_score</span> <span class=\"c1\"># mean accuracy over folds</span>\n",
       "\n",
       "<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;__main__&quot;</span><span class=\"p\">:</span>\n",
       "    <span class=\"n\">train_mlp</span><span class=\"p\">()</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn} \\PY{k+kn}{import} \\PY{n}{datasets}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{neural\\PYZus{}network} \\PY{k+kn}{import} \\PY{n}{MLPClassifier}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{cross\\PYZus{}val\\PYZus{}score}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{omegaconf} \\PY{k+kn}{import} \\PY{n}{DictConfig}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{hydra}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} We load the digits dataset}\n",
       "\\PY{n}{digits} \\PY{o}{=} \\PY{n}{datasets}\\PY{o}{.}\\PY{n}{load\\PYZus{}digits}\\PY{p}{(}\\PY{p}{)}\n",
       "\\PY{n}{X}\\PY{p}{,} \\PY{n}{y} \\PY{o}{=} \\PY{n}{digits}\\PY{o}{.}\\PY{n}{data}\\PY{p}{,} \\PY{n}{digits}\\PY{o}{.}\\PY{n}{target}\n",
       "\n",
       "\\PY{n}{X\\PYZus{}train}\\PY{p}{,} \\PY{n}{X\\PYZus{}test}\\PY{p}{,} \\PY{n}{y\\PYZus{}train}\\PY{p}{,} \\PY{n}{y\\PYZus{}test} \\PY{o}{=} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\\PY{p}{(}\\PY{n}{X}\\PY{p}{,} \\PY{n}{y}\\PY{p}{,} \\PY{n}{test\\PYZus{}size}\\PY{o}{=}\\PY{l+m+mf}{0.33}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{n+nd}{@hydra}\\PY{o}{.}\\PY{n}{main}\\PY{p}{(}\\PY{n}{version\\PYZus{}base}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \\PY{n}{config\\PYZus{}path}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{configs}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{config\\PYZus{}name}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{base}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{k}{def} \\PY{n+nf}{train\\PYZus{}mlp}\\PY{p}{(}\\PY{n}{cfg}\\PY{p}{:} \\PY{n}{DictConfig}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n+nb}{float}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} we want to have reproducible training}\n",
       "    \\PY{n}{np}\\PY{o}{.}\\PY{n}{random}\\PY{o}{.}\\PY{n}{seed}\\PY{p}{(}\\PY{n}{seed}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{seed}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} for illustrative purposes, you can reduce max\\PYZus{}iter drastically here}\n",
       "    \\PY{n}{classifier} \\PY{o}{=} \\PY{n}{MLPClassifier}\\PY{p}{(}\\PY{n}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{p}{,} \\PY{n}{max\\PYZus{}iter}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{max\\PYZus{}iter}\\PY{p}{,} \\PY{n}{activation}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{activation}\\PY{p}{,} \\PY{n}{solver}\\PY{o}{=}\\PY{n}{cfg}\\PY{o}{.}\\PY{n}{solver}\\PY{p}{)}\n",
       "    \\PY{n}{scores} \\PY{o}{=} \\PY{n}{cross\\PYZus{}val\\PYZus{}score}\\PY{p}{(}\\PY{n}{classifier}\\PY{p}{,} \\PY{n}{X\\PYZus{}train}\\PY{p}{,} \\PY{n}{y\\PYZus{}train}\\PY{p}{,} \\PY{n}{cv}\\PY{o}{=}\\PY{l+m+mi}{5}\\PY{p}{)}\n",
       "\n",
       "    \\PY{n}{mean\\PYZus{}score} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{n}{scores}\\PY{p}{)}\n",
       "\n",
       "    \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Mean accuracy: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{mean\\PYZus{}score}\\PY{l+s+si}{:}\\PY{l+s+s2}{.4f}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{return} \\PY{n}{mean\\PYZus{}score} \\PY{c+c1}{\\PYZsh{} mean accuracy over folds}\n",
       "\n",
       "\\PY{k}{if} \\PY{n+nv+vm}{\\PYZus{}\\PYZus{}name\\PYZus{}\\PYZus{}} \\PY{o}{==} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZus{}\\PYZus{}main\\PYZus{}\\PYZus{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:}\n",
       "    \\PY{n}{train\\PYZus{}mlp}\\PY{p}{(}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn import datasets\n",
       "from sklearn.neural_network import MLPClassifier\n",
       "from sklearn.model_selection import cross_val_score\n",
       "import numpy as np\n",
       "from omegaconf import DictConfig\n",
       "import hydra\n",
       "\n",
       "# We load the digits dataset\n",
       "digits = datasets.load_digits()\n",
       "X, y = digits.data, digits.target\n",
       "\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
       "\n",
       "\n",
       "@hydra.main(version_base=None, config_path=\"configs\", config_name=\"base\")\n",
       "def train_mlp(cfg: DictConfig) -> float:\n",
       "    # we want to have reproducible training\n",
       "    np.random.seed(seed=cfg.seed)\n",
       "\n",
       "    # for illustrative purposes, you can reduce max_iter drastically here\n",
       "    classifier = MLPClassifier(hidden_layer_sizes=cfg.hidden_layer_sizes, max_iter=cfg.max_iter, activation=cfg.activation, solver=cfg.solver)\n",
       "    scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
       "\n",
       "    mean_score = np.mean(scores)\n",
       "\n",
       "    print(f\"Mean accuracy: {mean_score:.4f}\")\n",
       "\n",
       "    return mean_score # mean accuracy over folds\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    train_mlp()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Code(filename=\"hydra_tutorial/classic_pipeline.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we let it run, let's have a look at the configuration file.\n",
    "This will be our default as decorated by hydra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"c1\"># @package _global_</span>\n",
       "<span class=\"nt\">defaults</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">  </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">_self_</span>\n",
       "<span class=\"w\">  </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"nt\">override hydra/launcher</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">joblib</span>\n",
       "<span class=\"w\">  </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"nt\">override hydra/job_logging</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">colorlog</span>\n",
       "<span class=\"w\">  </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"nt\">override hydra/hydra_logging</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">colorlog</span>\n",
       "\n",
       "<span class=\"nt\">seed</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">1234</span>\n",
       "<span class=\"nt\">hidden_layer_sizes</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p p-Indicator\">[</span><span class=\"nv\">100</span><span class=\"p p-Indicator\">,]</span>\n",
       "<span class=\"nt\">max_iter</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">100</span>\n",
       "<span class=\"nt\">activation</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s\">&#39;relu&#39;</span>\n",
       "<span class=\"nt\">solver</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s\">&#39;adam&#39;</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{c+c1}{\\PYZsh{} @package \\PYZus{}global\\PYZus{}}\n",
       "\\PY{n+nt}{defaults}\\PY{p}{:}\n",
       "\\PY{+w}{  }\\PY{p+pIndicator}{\\PYZhy{}}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{\\PYZus{}self\\PYZus{}}\n",
       "\\PY{+w}{  }\\PY{p+pIndicator}{\\PYZhy{}}\\PY{+w}{ }\\PY{n+nt}{override hydra/launcher}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{joblib}\n",
       "\\PY{+w}{  }\\PY{p+pIndicator}{\\PYZhy{}}\\PY{+w}{ }\\PY{n+nt}{override hydra/job\\PYZus{}logging}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{colorlog}\n",
       "\\PY{+w}{  }\\PY{p+pIndicator}{\\PYZhy{}}\\PY{+w}{ }\\PY{n+nt}{override hydra/hydra\\PYZus{}logging}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{colorlog}\n",
       "\n",
       "\\PY{n+nt}{seed}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{1234}\n",
       "\\PY{n+nt}{hidden\\PYZus{}layer\\PYZus{}sizes}\\PY{p}{:}\\PY{+w}{ }\\PY{p+pIndicator}{[}\\PY{n+nv}{100}\\PY{p+pIndicator}{,}\\PY{p+pIndicator}{]}\n",
       "\\PY{n+nt}{max\\PYZus{}iter}\\PY{p}{:}\\PY{+w}{ }\\PY{l+lScalar+lScalarPlain}{100}\n",
       "\\PY{n+nt}{activation}\\PY{p}{:}\\PY{+w}{ }\\PY{l+s}{\\PYZsq{}}\\PY{l+s}{relu}\\PY{l+s}{\\PYZsq{}}\n",
       "\\PY{n+nt}{solver}\\PY{p}{:}\\PY{+w}{ }\\PY{l+s}{\\PYZsq{}}\\PY{l+s}{adam}\\PY{l+s}{\\PYZsq{}}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "# @package _global_\n",
       "defaults:\n",
       "  - _self_\n",
       "  - override hydra/launcher: joblib\n",
       "  - override hydra/job_logging: colorlog\n",
       "  - override hydra/hydra_logging: colorlog\n",
       "\n",
       "seed: 1234\n",
       "hidden_layer_sizes: [100,]\n",
       "max_iter: 100\n",
       "activation: 'relu'\n",
       "solver: 'adam'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Code(filename=\"hydra_tutorial/configs/base.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.9626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline.py'], returncode=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\"python hydra_tutorial/classic_pipeline.py\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to pass arguments via the commandline.\n",
    "This is easily possible with the [override syntax](https://hydra.cc/docs/advanced/override_grammar/basic/).\n",
    "Let's vary the hidden layer sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.8945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline.py', 'hidden_layer_sizes=[10,10,10]'], returncode=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\"python hydra_tutorial/classic_pipeline.py hidden_layer_sizes=[10,10,10]\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what really comes in handy is the ability to grid of parameter settings.\n",
    "First, to factor out randomness we want to run different seeds.\n",
    "Then, we would like to check different settings, e.g. different hidden layer sizes and different activation functions.\n",
    "\n",
    "For this we will add a list of parameter values and the flag `-m` or `--multirun` to indicate that this is a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2023-11-02 22:23:42,063\u001b[0m][\u001b[35mHYDRA\u001b[0m] Joblib.Parallel(n_jobs=-1,backend=loky,prefer=processes,require=None,verbose=0,timeout=None,pre_dispatch=2*n_jobs,batch_size=auto,temp_folder=None,max_nbytes=None,mmap_mode=r) is launching 2 jobs\u001b[0m\n",
      "[\u001b[36m2023-11-02 22:23:42,063\u001b[0m][\u001b[35mHYDRA\u001b[0m] Launching jobs, sweep output dir : multirun/2023-11-02/22-23-41\u001b[0m\n",
      "[\u001b[36m2023-11-02 22:23:42,063\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#0 : hidden_layer_sizes=[100]\u001b[0m\n",
      "[\u001b[36m2023-11-02 22:23:42,063\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t#1 : hidden_layer_sizes=[10,10,10]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.8945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/numina/micromamba/envs/hydratutorial/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.9626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'hydra_tutorial/classic_pipeline.py', 'hidden_layer_sizes=[100],[10,10,10]', '-m'], returncode=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\"python hydra_tutorial/classic_pipeline.py hidden_layer_sizes=[100],[10,10,10] -m\".split(\" \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
